#!/usr/bin/env python3
"""
å†…ç½®æ–‡æ¡£ç´¢å¼•å™¨
è‡ªåŠ¨ç´¢å¼• ai-coding-java æ’ä»¶ä¸­çš„å†…ç½®æ–‡æ¡£
"""

import os
import sys
import asyncio
from pathlib import Path
from typing import List, Dict, Any

# æ·»åŠ è„šæœ¬ç›®å½•åˆ° Python è·¯å¾„
script_dir = Path(__file__).parent
sys.path.insert(0, str(script_dir))

from document_processor import DocumentProcessorFactory
from simple_vectorizer import SimpleDocumentVectorizer
from config_loader import Context7ConfigLoader

class BuiltinDocumentIndexer:
    def __init__(self):
        self.config_loader = Context7ConfigLoader()
        self.doc_processor_factory = DocumentProcessorFactory()

        # è·å–æ’ä»¶æ ¹ç›®å½•
        self.plugin_root = Path(os.environ.get('CLAUDE_PLUGIN_ROOT',
                                             script_dir.parent.parent.parent))

        # å†…ç½®æ–‡æ¡£è·¯å¾„
        self.builtin_docs_path = self.plugin_root / "docs"

        # åˆå§‹åŒ–å‘é‡åŒ–å¼•æ“
        data_dir = self.config_loader.load_config().get('cache', {}).get('storage_path',
                                                                      str(script_dir.parent / "data"))
        self.vectorizer = SimpleDocumentVectorizer(data_dir=data_dir)

    async def index_all_builtin_docs(self):
        """ç´¢å¼•æ‰€æœ‰å†…ç½®æ–‡æ¡£"""
        print("ğŸš€ å¼€å§‹ç´¢å¼•å†…ç½®æ–‡æ¡£...")
        print(f"ğŸ“ æ’ä»¶æ ¹ç›®å½•: {self.plugin_root}")
        print(f"ğŸ“š æ–‡æ¡£ç›®å½•: {self.builtin_docs_path}")

        if not self.builtin_docs_path.exists():
            print(f"âŒ æ–‡æ¡£ç›®å½•ä¸å­˜åœ¨: {self.builtin_docs_path}")
            return 0

        # æŸ¥æ‰¾æ‰€æœ‰æ”¯æŒçš„æ–‡æ¡£æ–‡ä»¶
        supported_extensions = []
        for processor in self.doc_processor_factory.processors.values():
            supported_extensions.extend(processor.supported_extensions())

        doc_files = []
        for ext in supported_extensions:
            doc_files.extend(self.builtin_docs_path.rglob(f"*{ext}"))

        if not doc_files:
            print("âŒ æœªæ‰¾åˆ°æ”¯æŒçš„æ–‡æ¡£æ–‡ä»¶")
            return 0

        print(f"ğŸ“„ æ‰¾åˆ° {len(doc_files)} ä¸ªæ–‡æ¡£æ–‡ä»¶")

        indexed_count = 0
        errors = []

        for doc_file in doc_files:
            try:
                print(f"\nğŸ”„ æ­£åœ¨å¤„ç†: {doc_file.relative_to(self.builtin_docs_path)}")

                # å¤„ç†æ–‡æ¡£
                document = await self.doc_processor_factory.process_document(str(doc_file))
                if not document:
                    print(f"âš ï¸  è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶: {doc_file}")
                    continue

                # æ ‡è®°ä¸ºå†…ç½®æ–‡æ¡£
                document['metadata']['source'] = 'builtin'
                document['metadata']['category'] = self._categorize_doc(str(doc_file))
                document['doc_id'] = f"builtin_{document['doc_id']}"

                # å‘é‡åŒ–å­˜å‚¨
                vector_ids = await self.vectorizer.vectorize_and_store(document)

                indexed_count += 1
                print(f"âœ… ç´¢å¼•æˆåŠŸ: {document['title']} ({len(vector_ids)} å—)")

            except Exception as e:
                error_msg = f"âŒ ç´¢å¼•å¤±è´¥ {doc_file}: {e}"
                print(error_msg)
                errors.append(error_msg)

        print(f"\nğŸ“Š å†…ç½®æ–‡æ¡£ç´¢å¼•å®Œæˆ")
        print(f"âœ… æˆåŠŸç´¢å¼•: {indexed_count} ä¸ªæ–‡æ¡£")
        if errors:
            print(f"âŒ å¤±è´¥: {len(errors)} ä¸ªæ–‡æ¡£")
            for error in errors:
                print(f"   {error}")

        return indexed_count

    def _categorize_doc(self, file_path: str) -> str:
        """æ ¹æ®æ–‡ä»¶è·¯å¾„ç¡®å®šæ–‡æ¡£åˆ†ç±»"""
        path_obj = Path(file_path)
        relative_path = path_obj.relative_to(self.builtin_docs_path)

        if 'guides' in str(relative_path):
            return 'guide'
        elif 'rules' in str(relative_path):
            return 'standards'
        elif 'templates' in str(relative_path):
            return 'template'
        elif 'api' in str(relative_path):
            return 'api'
        else:
            return 'general'

    async def list_indexed_documents(self):
        """åˆ—å‡ºå·²ç´¢å¼•çš„å†…ç½®æ–‡æ¡£"""
        print("\nğŸ“‹ å·²ç´¢å¼•çš„å†…ç½®æ–‡æ¡£:")

        try:
            documents = await self.vectorizer.list_documents("builtin")

            if not documents:
                print("   æš‚æ— å·²ç´¢å¼•çš„å†…ç½®æ–‡æ¡£")
                return

            for i, doc in enumerate(documents, 1):
                print(f"   {i}. ğŸ“„ {doc['title']}")
                print(f"      ğŸ†” {doc['doc_id']}")
                print(f"      ğŸ“Š {doc['format']} | {doc['chunk_count']} å—")
                print(f"      ğŸ“‚ {doc['file_path']}")
                print()

        except Exception as e:
            print(f"âŒ è·å–æ–‡æ¡£åˆ—è¡¨å¤±è´¥: {e}")

async def main():
    """ä¸»å‡½æ•°"""
    try:
        indexer = BuiltinDocumentIndexer()

        # æ£€æŸ¥æ˜¯å¦åº”è¯¥åˆ—å‡ºæ–‡æ¡£
        if len(sys.argv) > 1 and sys.argv[1] == '--list':
            await indexer.list_indexed_documents()
            return

        # ç´¢å¼•æ‰€æœ‰å†…ç½®æ–‡æ¡£
        await indexer.index_all_builtin_docs()

        # åˆ—å‡ºç´¢å¼•ç»“æœ
        await indexer.list_indexed_documents()

    except KeyboardInterrupt:
        print("\nâš ï¸  ç´¢å¼•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"âŒ ç´¢å¼•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main())