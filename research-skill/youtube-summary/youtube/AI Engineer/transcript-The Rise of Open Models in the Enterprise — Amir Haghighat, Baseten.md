# The Rise of Open Models in the Enterprise â€” Amir Haghighat, Baseten

**Video URL:** https://www.youtube.com/watch?v=3WV1vT0B0cg

---

## Full Transcript

### [00:00 - 01:00]

**[00:16]** Yeah. Hi everyone. My my name is Amir.

**[00:16]** Yeah. Hi everyone. My my name is Amir. I'm co-founder and CTO of B 10 uh the

**[00:19]** I'm co-founder and CTO of B 10 uh the

**[00:19]** I'm co-founder and CTO of B 10 uh the inference company. But I'm not here to

**[00:21]** inference company. But I'm not here to

**[00:21]** inference company. But I'm not here to talk about B 10. I'm here to talk about

**[00:24]** talk about B 10. I'm here to talk about

**[00:24]** talk about B 10. I'm here to talk about the adoption of AI in the enterprise.

**[00:27]** the adoption of AI in the enterprise.

**[00:28]** the adoption of AI in the enterprise. why we should care about it and how it's

**[00:31]** why we should care about it and how it's

**[00:31]** why we should care about it and how it's going uh based on what we've seen. So,

**[00:34]** going uh based on what we've seen. So,

**[00:34]** going uh based on what we've seen. So, uh first why why we should uh care about

**[00:37]** uh first why why we should uh care about

**[00:37]** uh first why why we should uh care about it. Um ultimately, um we've heard this

**[00:42]** it. Um ultimately, um we've heard this

**[00:42]** it. Um ultimately, um we've heard this before is like, hey, is there hype in

**[00:43]** before is like, hey, is there hype in

**[00:43]** before is like, hey, is there hype in the market? You know, is is AI hyped?

**[00:45]** the market? You know, is is AI hyped?

**[00:45]** the market? You know, is is AI hyped? And like it probably is, but uh the the

**[00:48]** And like it probably is, but uh the the

**[00:48]** And like it probably is, but uh the the evidence that a lot of people point to

**[00:51]** evidence that a lot of people point to

**[00:51]** evidence that a lot of people point to that there's hype here is that the

**[00:53]** that there's hype here is that the

**[00:53]** that there's hype here is that the adoption in enterprise has been slow. uh

**[00:55]** adoption in enterprise has been slow. uh

**[00:55]** adoption in enterprise has been slow. uh you know you've I've heard this so many

**[00:57]** you know you've I've heard this so many

**[00:57]** you know you've I've heard this so many times that like you know enterprises are


### [01:00 - 02:00]

**[01:00]** times that like you know enterprises are

**[01:00]** times that like you know enterprises are are are slow to adopt uh and uh and and

**[01:03]** are are slow to adopt uh and uh and and

**[01:03]** are are slow to adopt uh and uh and and and that that has an implication uh if

**[01:06]** and that that has an implication uh if

**[01:06]** and that that has an implication uh if if that is true that has implication for

**[01:08]** if that is true that has implication for

**[01:08]** if that is true that has implication for really the impact of AI uh and how large

**[01:10]** really the impact of AI uh and how large

**[01:10]** really the impact of AI uh and how large it can be and whether it is truly a hype

**[01:13]** it can be and whether it is truly a hype

**[01:13]** it can be and whether it is truly a hype uh or or real um and the reason is that

**[01:16]** uh or or real um and the reason is that

**[01:16]** uh or or real um and the reason is that enterprises are massive like the reach

**[01:18]** enterprises are massive like the reach

**[01:18]** enterprises are massive like the reach is massive um they have all the money uh

**[01:21]** is massive um they have all the money uh

**[01:21]** is massive um they have all the money uh and uh and if if they're slow in

**[01:23]** and uh and if if they're slow in

**[01:23]** and uh and if if they're slow in adopting uh then uh that that paradigm

**[01:26]** adopting uh then uh that that paradigm

**[01:26]** adopting uh then uh that that paradigm shift that we're talking about that uh

**[01:28]** shift that we're talking about that uh

**[01:28]** shift that we're talking about that uh will be slow uh to to materialize.

**[01:31]** will be slow uh to to materialize.

**[01:31]** will be slow uh to to materialize. So, but I'm here to tell you based on

**[01:33]** So, but I'm here to tell you based on

**[01:33]** So, but I'm here to tell you based on what I've learned uh about adoption of

**[01:35]** what I've learned uh about adoption of

**[01:35]** what I've learned uh about adoption of AI in enterprise um why why me? Why um

**[01:39]** AI in enterprise um why why me? Why um

**[01:39]** AI in enterprise um why why me? Why um uh because we're we're happen to sit

**[01:42]** uh because we're we're happen to sit

**[01:42]** uh because we're we're happen to sit somewhere interesting. We happen to sell

**[01:44]** somewhere interesting. We happen to sell

**[01:44]** somewhere interesting. We happen to sell to enterprises uh and and so over the

**[01:47]** to enterprises uh and and so over the

**[01:47]** to enterprises uh and and so over the past companies six years old but over

**[01:49]** past companies six years old but over

**[01:49]** past companies six years old but over the past two years uh you know in

**[01:51]** the past two years uh you know in

**[01:51]** the past two years uh you know in particular talked to honestly 100 plus

**[01:54]** particular talked to honestly 100 plus

**[01:54]** particular talked to honestly 100 plus enterprises from software companies that

**[01:56]** enterprises from software companies that

**[01:56]** enterprises from software companies that are public to literally soft drink

**[01:58]** are public to literally soft drink

**[01:58]** are public to literally soft drink companies uh that that are you know


### [02:00 - 03:00]

**[02:01]** companies uh that that are you know

**[02:01]** companies uh that that are you know fortune fortune 50 um and uh and I've

**[02:04]** fortune fortune 50 um and uh and I've

**[02:04]** fortune fortune 50 um and uh and I've seen patterns that I want to share those

**[02:06]** seen patterns that I want to share those

**[02:06]** seen patterns that I want to share those patterns with you uh one bias that I

**[02:08]** patterns with you uh one bias that I

**[02:08]** patterns with you uh one bias that I have uh is that I'm I don't sell a

**[02:12]** have uh is that I'm I don't sell a

**[02:12]** have uh is that I'm I don't sell a verticalized

**[02:13]** verticalized

**[02:13]** verticalized AI tooling. I I sell a very horizontal

**[02:15]** AI tooling. I I sell a very horizontal

**[02:15]** AI tooling. I I sell a very horizontal AI tooling and this is important. So,

**[02:17]** AI tooling and this is important. So,

**[02:18]** AI tooling and this is important. So, enterprises are adopting vertical

**[02:19]** enterprises are adopting vertical

**[02:19]** enterprises are adopting vertical solutions, you know, um AI for sales, AI

**[02:22]** solutions, you know, um AI for sales, AI

**[02:22]** solutions, you know, um AI for sales, AI for marketing, um AI for customer

**[02:24]** for marketing, um AI for customer

**[02:24]** for marketing, um AI for customer service. You just heard from Clay from

**[02:26]** service. You just heard from Clay from

**[02:26]** service. You just heard from Clay from Sierra. Um that adoption is happening.

**[02:28]** Sierra. Um that adoption is happening.

**[02:28]** Sierra. Um that adoption is happening. But I think for the true value to get

**[02:30]** But I think for the true value to get

**[02:30]** But I think for the true value to get unlocked, uh we need to see enterprises

**[02:32]** unlocked, uh we need to see enterprises

**[02:32]** unlocked, uh we need to see enterprises actually build with AI. Um the analogy

**[02:35]** actually build with AI. Um the analogy

**[02:35]** actually build with AI. Um the analogy that I use is that if in the 2000s uh

**[02:38]** that I use is that if in the 2000s uh

**[02:38]** that I use is that if in the 2000s uh enterprises were u not really building

**[02:42]** enterprises were u not really building

**[02:42]** enterprises were u not really building tech themselves and and were just buying

**[02:44]** tech themselves and and were just buying

**[02:44]** tech themselves and and were just buying uh Salesforce uh or uh you know products

**[02:48]** uh Salesforce uh or uh you know products

**[02:48]** uh Salesforce uh or uh you know products like that verticalized product products

**[02:49]** like that verticalized product products

**[02:49]** like that verticalized product products like that then then the the tech

**[02:52]** like that then then the the tech

**[02:52]** like that then then the the tech industry would just not be as big. Uh

**[02:54]** industry would just not be as big. Uh

**[02:54]** industry would just not be as big. Uh companies like Snowflake and data bricks

**[02:56]** companies like Snowflake and data bricks

**[02:56]** companies like Snowflake and data bricks and data dog would not exist or would

**[02:58]** and data dog would not exist or would

**[02:58]** and data dog would not exist or would not exist to the shape that that they


### [03:00 - 04:00]

**[03:00]** not exist to the shape that that they

**[03:00]** not exist to the shape that that they do. And so I really think that the value

**[03:01]** do. And so I really think that the value

**[03:01]** do. And so I really think that the value is ultimately unlocked once enterprises

**[03:03]** is ultimately unlocked once enterprises

**[03:03]** is ultimately unlocked once enterprises feel comfortable to actually build with

**[03:05]** feel comfortable to actually build with

**[03:05]** feel comfortable to actually build with AI themselves as opposed to just by uh

**[03:08]** AI themselves as opposed to just by uh

**[03:08]** AI themselves as opposed to just by uh verticalized tooling. So let's talk

**[03:10]** verticalized tooling. So let's talk

**[03:10]** verticalized tooling. So let's talk about the the journey uh the the journey

**[03:13]** about the the journey uh the the journey

**[03:13]** about the the journey uh the the journey that they go through. Um uh they they

**[03:16]** that they go through. Um uh they they

**[03:16]** that they go through. Um uh they they all start with OpenAI and anthropic you

**[03:19]** all start with OpenAI and anthropic you

**[03:19]** all start with OpenAI and anthropic you know enterprises they're like us um you

**[03:21]** know enterprises they're like us um you

**[03:21]** know enterprises they're like us um you know for for good reasons. It's just so

**[03:23]** know for for good reasons. It's just so

**[03:23]** know for for good reasons. It's just so easy to get started. Um it's just they

**[03:25]** easy to get started. Um it's just they

**[03:25]** easy to get started. Um it's just they do it differently from from the rest of

**[03:26]** do it differently from from the rest of

**[03:26]** do it differently from from the rest of us in that they they have their own uh

**[03:29]** us in that they they have their own uh

**[03:29]** us in that they they have their own uh dedicated deployments of of these models

**[03:31]** dedicated deployments of of these models

**[03:31]** dedicated deployments of of these models on Azure or or AWS um and um for for

**[03:36]** on Azure or or AWS um and um for for

**[03:36]** on Azure or or AWS um and um for for reasons around security and privacy and

**[03:37]** reasons around security and privacy and

**[03:37]** reasons around security and privacy and and all that. Um, and then they they get

**[03:39]** and all that. Um, and then they they get

**[03:39]** and all that. Um, and then they they get their engineers. A lot of times they're

**[03:41]** their engineers. A lot of times they're

**[03:41]** their engineers. A lot of times they're more, you know, predictive uh ML teams

**[03:44]** more, you know, predictive uh ML teams

**[03:44]** more, you know, predictive uh ML teams uh to become AI teams and and and build

**[03:46]** uh to become AI teams and and and build

**[03:46]** uh to become AI teams and and and build on top of these. Um, and they're they're

**[03:49]** on top of these. Um, and they're they're

**[03:50]** on top of these. Um, and they're they're happy with that. And if they can

**[03:51]** happy with that. And if they can

**[03:51]** happy with that. And if they can continue doing that, they will uh

**[03:53]** continue doing that, they will uh

**[03:53]** continue doing that, they will uh because uh there's just a a lot of

**[03:56]** because uh there's just a a lot of

**[03:56]** because uh there's just a a lot of inertia in in in in sticking to that if

**[03:58]** inertia in in in in sticking to that if

**[03:58]** inertia in in in in sticking to that if it actually works. Uh sticking to closed


### [04:00 - 05:00]

**[04:00]** it actually works. Uh sticking to closed

**[04:00]** it actually works. Uh sticking to closed models, so easy to use, API based, you

**[04:03]** models, so easy to use, API based, you

**[04:03]** models, so easy to use, API based, you know, build on top of it.

**[04:05]** know, build on top of it.

**[04:05]** know, build on top of it. Um, but we're seeing cracks in that

**[04:08]** Um, but we're seeing cracks in that

**[04:08]** Um, but we're seeing cracks in that assumption. Uh, and so let me let me

**[04:10]** assumption. Uh, and so let me let me

**[04:10]** assumption. Uh, and so let me let me tell you what what I've seen going back

**[04:11]** tell you what what I've seen going back

**[04:12]** tell you what what I've seen going back in time and and how that's changed over

**[04:13]** in time and and how that's changed over

**[04:13]** in time and and how that's changed over time. So in 2023, I remember like going

**[04:17]** time. So in 2023, I remember like going

**[04:17]** time. So in 2023, I remember like going and trying to sell to enterprises and

**[04:18]** and trying to sell to enterprises and

**[04:18]** and trying to sell to enterprises and and and the terms toying around came up

**[04:20]** and and the terms toying around came up

**[04:20]** and and the terms toying around came up quite a bit. And I heard this actually

**[04:22]** quite a bit. And I heard this actually

**[04:22]** quite a bit. And I heard this actually literally from um CIO of a massive

**[04:25]** literally from um CIO of a massive

**[04:25]** literally from um CIO of a massive insurance company uh back then. is like,

**[04:27]** insurance company uh back then. is like,

**[04:27]** insurance company uh back then. is like, "Yeah, we put a dedicated deployment of

**[04:29]** "Yeah, we put a dedicated deployment of

**[04:29]** "Yeah, we put a dedicated deployment of OpenAI uh of of GPD4 or GPD3 um uh so

**[04:33]** OpenAI uh of of GPD4 or GPD3 um uh so

**[04:33]** OpenAI uh of of GPD4 or GPD3 um uh so that our engineers can toy around with

**[04:35]** that our engineers can toy around with

**[04:35]** that our engineers can toy around with it." Kind of like almost dismissively

**[04:37]** it." Kind of like almost dismissively

**[04:37]** it." Kind of like almost dismissively talking about is like, "Hey, go build

**[04:38]** talking about is like, "Hey, go build

**[04:38]** talking about is like, "Hey, go build something cute." Um that started to

**[04:41]** something cute." Um that started to

**[04:41]** something cute." Um that started to change in 2024. We saw actual production

**[04:44]** change in 2024. We saw actual production

**[04:44]** change in 2024. We saw actual production uh use cases again built on top of these

**[04:47]** uh use cases again built on top of these

**[04:47]** uh use cases again built on top of these closed models. Um I would say like 40 50

**[04:50]** closed models. Um I would say like 40 50

**[04:50]** closed models. Um I would say like 40 50 out of the hundred like had something in

**[04:52]** out of the hundred like had something in

**[04:52]** out of the hundred like had something in production uh uh in that year. Um and

**[04:56]** production uh uh in that year. Um and

**[04:56]** production uh uh in that year. Um and then in 2025 this year something changed

**[04:59]** then in 2025 this year something changed

**[04:59]** then in 2025 this year something changed uh and and and is palpable from at least


### [05:00 - 06:00]

**[05:01]** uh and and and is palpable from at least

**[05:02]** uh and and and is palpable from at least from where I'm sitting. Uh and and and

**[05:04]** from where I'm sitting. Uh and and and

**[05:04]** from where I'm sitting. Uh and and and the change is that there are cracks in

**[05:05]** the change is that there are cracks in

**[05:05]** the change is that there are cracks in that assumption. There are cracks in the

**[05:07]** that assumption. There are cracks in the

**[05:07]** that assumption. There are cracks in the assumption that we can actually build on

**[05:08]** assumption that we can actually build on

**[05:08]** assumption that we can actually build on top of these closed frontier models uh

**[05:11]** top of these closed frontier models uh

**[05:11]** top of these closed frontier models uh indefinitely.

**[05:14]** indefinitely.

**[05:14]** indefinitely. So what are those cracks? Um uh I'll

**[05:16]** So what are those cracks? Um uh I'll

**[05:16]** So what are those cracks? Um uh I'll tell you what the cracks are not. And

**[05:18]** tell you what the cracks are not. And

**[05:18]** tell you what the cracks are not. And there's some misconceptions over here.

**[05:20]** there's some misconceptions over here.

**[05:20]** there's some misconceptions over here. Um I'll tell you what they're not. Uh so

**[05:22]** Um I'll tell you what they're not. Uh so

**[05:22]** Um I'll tell you what they're not. Uh so like often people say oh because people

**[05:24]** like often people say oh because people

**[05:24]** like often people say oh because people like enterprises don't want to have

**[05:25]** like enterprises don't want to have

**[05:25]** like enterprises don't want to have vendor locking. I don't hear that

**[05:27]** vendor locking. I don't hear that

**[05:27]** vendor locking. I don't hear that honestly. Uh like we go and talk to

**[05:29]** honestly. Uh like we go and talk to

**[05:29]** honestly. Uh like we go and talk to them. I think I know why is because one

**[05:32]** them. I think I know why is because one

**[05:32]** them. I think I know why is because one there's a few of them now. You know you

**[05:33]** there's a few of them now. You know you

**[05:33]** there's a few of them now. You know you can go open AI anthropic Google has been

**[05:35]** can go open AI anthropic Google has been

**[05:35]** can go open AI anthropic Google has been coming up pretty well. They're somewhat

**[05:37]** coming up pretty well. They're somewhat

**[05:37]** coming up pretty well. They're somewhat interoperable uh at a certain level like

**[05:40]** interoperable uh at a certain level like

**[05:40]** interoperable uh at a certain level like they all use OpenAI specs. So like

**[05:42]** they all use OpenAI specs. So like

**[05:42]** they all use OpenAI specs. So like building on top of them. Yeah you might

**[05:43]** building on top of them. Yeah you might

**[05:43]** building on top of them. Yeah you might have to like do your emails again and

**[05:45]** have to like do your emails again and

**[05:45]** have to like do your emails again and and um do some prompt tuning but

**[05:48]** and um do some prompt tuning but

**[05:48]** and um do some prompt tuning but generally you can go from one to the

**[05:49]** generally you can go from one to the

**[05:49]** generally you can go from one to the other. So vendor lockin is not something

**[05:51]** other. So vendor lockin is not something

**[05:51]** other. So vendor lockin is not something that I hear about. Um ballooning cost I

**[05:54]** that I hear about. Um ballooning cost I

**[05:54]** that I hear about. Um ballooning cost I I didn't hear that last year. Um and I

**[05:57]** I didn't hear that last year. Um and I

**[05:58]** I didn't hear that last year. Um and I and I know why is because when I asked

**[05:59]** and I know why is because when I asked


### [06:00 - 07:00]

**[06:00]** and I know why is because when I asked them they say look uh the price per

**[06:02]** them they say look uh the price per

**[06:02]** them they say look uh the price per token is plummeting and we we just

**[06:04]** token is plummeting and we we just

**[06:04]** token is plummeting and we we just talked about this like right before

**[06:05]** talked about this like right before

**[06:05]** talked about this like right before this. Uh and that's the they were saying

**[06:08]** this. Uh and that's the they were saying

**[06:08]** this. Uh and that's the they were saying that problem will just take care of

**[06:10]** that problem will just take care of

**[06:10]** that problem will just take care of itself. um compliance, privacy, security

**[06:13]** itself. um compliance, privacy, security

**[06:13]** itself. um compliance, privacy, security also not problems because these frontier

**[06:15]** also not problems because these frontier

**[06:15]** also not problems because these frontier model companies kind of take care of

**[06:17]** model companies kind of take care of

**[06:17]** model companies kind of take care of that with the help of the CSPs, with the

**[06:18]** that with the help of the CSPs, with the

**[06:18]** that with the help of the CSPs, with the help of the the the cloud providers so

**[06:20]** help of the the the cloud providers so

**[06:20]** help of the the the cloud providers so that these models are running in a

**[06:22]** that these models are running in a

**[06:22]** that these models are running in a dedicated way inside of their existing

**[06:24]** dedicated way inside of their existing

**[06:24]** dedicated way inside of their existing VPCs.

**[06:26]** VPCs.

**[06:26]** VPCs. Um if these aren't the the the cracks in

**[06:29]** Um if these aren't the the the cracks in

**[06:29]** Um if these aren't the the the cracks in that assumption of just use closed

**[06:31]** that assumption of just use closed

**[06:31]** that assumption of just use closed models, then then then what are the

**[06:32]** models, then then then what are the

**[06:32]** models, then then then what are the cracks? uh these these are uh the the

**[06:36]** cracks? uh these these are uh the the

**[06:36]** cracks? uh these these are uh the the the reasons that I have seen uh and and

**[06:38]** the reasons that I have seen uh and and

**[06:38]** the reasons that I have seen uh and and I'll go through them one by one uh and

**[06:40]** I'll go through them one by one uh and

**[06:40]** I'll go through them one by one uh and and go through like examples of these as

**[06:42]** and go through like examples of these as

**[06:42]** and go through like examples of these as well uh and uh and then at the end also

**[06:46]** well uh and uh and then at the end also

**[06:46]** well uh and uh and then at the end also talk about um you know if if these are

**[06:49]** talk about um you know if if these are

**[06:49]** talk about um you know if if these are the cracks then uh you know how do you

**[06:51]** the cracks then uh you know how do you

**[06:51]** the cracks then uh you know how do you get around them and and you know there

**[06:53]** get around them and and you know there

**[06:53]** get around them and and you know there be the dragons.

**[06:56]** be the dragons.

**[06:56]** be the dragons. So one is around quality. Look, none of

**[06:58]** So one is around quality. Look, none of

**[06:58]** So one is around quality. Look, none of these enterprises are in any sort of


### [07:00 - 08:00]

**[07:01]** these enterprises are in any sort of

**[07:01]** these enterprises are in any sort of misconception that they can build the

**[07:03]** misconception that they can build the

**[07:03]** misconception that they can build the next GP4 better than OpenAI can. That's

**[07:05]** next GP4 better than OpenAI can. That's

**[07:05]** next GP4 better than OpenAI can. That's just not the the reality. Not not as a

**[07:07]** just not the the reality. Not not as a

**[07:07]** just not the the reality. Not not as a gen general model at least. But for

**[07:09]** gen general model at least. But for

**[07:09]** gen general model at least. But for specific use cases, for specific tasks,

**[07:12]** specific use cases, for specific tasks,

**[07:12]** specific use cases, for specific tasks, we're seeing this where the the frontier

**[07:14]** we're seeing this where the the frontier

**[07:14]** we're seeing this where the the frontier models are not necessarily the right

**[07:16]** models are not necessarily the right

**[07:16]** models are not necessarily the right tool. Uh so the example uh I've seen

**[07:19]** tool. Uh so the example uh I've seen

**[07:20]** tool. Uh so the example uh I've seen this in a couple of big health plans is

**[07:21]** this in a couple of big health plans is

**[07:22]** this in a couple of big health plans is that they want to do medical document

**[07:24]** that they want to do medical document

**[07:24]** that they want to do medical document extraction. So they have millions of

**[07:26]** extraction. So they have millions of

**[07:26]** extraction. So they have millions of medical documents uh prior off and

**[07:29]** medical documents uh prior off and

**[07:29]** medical documents uh prior off and medical claims and and they're trying to

**[07:31]** medical claims and and they're trying to

**[07:31]** medical claims and and they're trying to get you know CPT like um procedure codes

**[07:33]** get you know CPT like um procedure codes

**[07:34]** get you know CPT like um procedure codes and diagnosis codes and and

**[07:35]** and diagnosis codes and and

**[07:35]** and diagnosis codes and and prescriptions uh and just giving that to

**[07:38]** prescriptions uh and just giving that to

**[07:38]** prescriptions uh and just giving that to you know claude or or GPT doesn't uh

**[07:40]** you know claude or or GPT doesn't uh

**[07:40]** you know claude or or GPT doesn't uh doesn't do it but they have the data uh

**[07:43]** doesn't do it but they have the data uh

**[07:43]** doesn't do it but they have the data uh over the years they've collected a lot

**[07:44]** over the years they've collected a lot

**[07:44]** over the years they've collected a lot of label data and they're like oh we can

**[07:46]** of label data and they're like oh we can

**[07:46]** of label data and they're like oh we can do better uh and and so that's that and

**[07:49]** do better uh and and so that's that and

**[07:49]** do better uh and and so that's that and and they actually did. That's one

**[07:51]** and they actually did. That's one

**[07:51]** and they actually did. That's one example. Another example is um on the

**[07:55]** example. Another example is um on the

**[07:55]** example. Another example is um on the voice side in particular on the

**[07:56]** voice side in particular on the

**[07:56]** voice side in particular on the transcription side like again staying in

**[07:59]** transcription side like again staying in

**[07:59]** transcription side like again staying in the healthcare space like understanding


### [08:00 - 09:00]

**[08:00]** the healthcare space like understanding

**[08:00]** the healthcare space like understanding medical jargon or like you know getting

**[08:02]** medical jargon or like you know getting

**[08:02]** medical jargon or like you know getting getting transcription models to

**[08:04]** getting transcription models to

**[08:04]** getting transcription models to understand medical jargon um that that

**[08:07]** understand medical jargon um that that

**[08:07]** understand medical jargon um that that has been another reason to not just use

**[08:09]** has been another reason to not just use

**[08:09]** has been another reason to not just use an API based generic model u but but

**[08:12]** an API based generic model u but but

**[08:12]** an API based generic model u but but inhouse it and do better than than what

**[08:14]** inhouse it and do better than than what

**[08:14]** inhouse it and do better than than what they can uh what they can do with just

**[08:16]** they can uh what they can do with just

**[08:16]** they can uh what they can do with just uh API based models. Another one is is

**[08:18]** uh API based models. Another one is is

**[08:18]** uh API based models. Another one is is around latency. Um look these these

**[08:22]** around latency. Um look these these

**[08:22]** around latency. Um look these these models um uh open anthropic even even

**[08:26]** models um uh open anthropic even even

**[08:26]** models um uh open anthropic even even you know the the big players that serve

**[08:27]** you know the the big players that serve

**[08:27]** you know the the big players that serve open source models behind shared APIs

**[08:30]** open source models behind shared APIs

**[08:30]** open source models behind shared APIs inherently they're optimized for high

**[08:33]** inherently they're optimized for high

**[08:33]** inherently they're optimized for high throughput and high QPS at the expense

**[08:35]** throughput and high QPS at the expense

**[08:35]** throughput and high QPS at the expense of latency but a lot of times we're

**[08:38]** of latency but a lot of times we're

**[08:38]** of latency but a lot of times we're seeing more and more now where latency

**[08:40]** seeing more and more now where latency

**[08:40]** seeing more and more now where latency is becoming very critical uh especially

**[08:43]** is becoming very critical uh especially

**[08:43]** is becoming very critical uh especially when you know the the AI AI voices or or

**[08:46]** when you know the the AI AI voices or or

**[08:46]** when you know the the AI AI voices or or AI phone calls uh latency starts really

**[08:48]** AI phone calls uh latency starts really

**[08:48]** AI phone calls uh latency starts really mattering

**[08:49]** mattering

**[08:49]** mattering uh time to first to talk and time to

**[08:51]** uh time to first to talk and time to

**[08:51]** uh time to first to talk and time to first sentence really starts mattering.

**[08:53]** first sentence really starts mattering.

**[08:53]** first sentence really starts mattering. Uh and you have to just think about

**[08:56]** Uh and you have to just think about

**[08:56]** Uh and you have to just think about things differently. Uh you can't just

**[08:59]** things differently. Uh you can't just

**[08:59]** things differently. Uh you can't just use the uh the the frontier models as is


### [09:00 - 10:00]

**[09:03]** use the uh the the frontier models as is

**[09:03]** use the uh the the frontier models as is because again they're optimized for

**[09:04]** because again they're optimized for

**[09:04]** because again they're optimized for something else.

**[09:07]** something else.

**[09:07]** something else. Um around the unit economics uh there's

**[09:09]** Um around the unit economics uh there's

**[09:09]** Um around the unit economics uh there's uh again like I said before like pricing

**[09:12]** uh again like I said before like pricing

**[09:12]** uh again like I said before like pricing they said this this will take care of

**[09:13]** they said this this will take care of

**[09:13]** they said this this will take care of itself. Uh then came this year and and

**[09:16]** itself. Uh then came this year and and

**[09:16]** itself. Uh then came this year and and as you saw in the previous talk from

**[09:18]** as you saw in the previous talk from

**[09:18]** as you saw in the previous talk from Michael that the agentic use cases

**[09:19]** Michael that the agentic use cases

**[09:20]** Michael that the agentic use cases ballooned uh and the when when when they

**[09:22]** ballooned uh and the when when when they

**[09:22]** ballooned uh and the when when when they balloon it's crazy like I've seen this

**[09:24]** balloon it's crazy like I've seen this

**[09:24]** balloon it's crazy like I've seen this like every single user action can result

**[09:26]** like every single user action can result

**[09:26]** like every single user action can result in literally 50 inference calls uh and

**[09:29]** in literally 50 inference calls uh and

**[09:29]** in literally 50 inference calls uh and and so suddenly the thing that you

**[09:30]** and so suddenly the thing that you

**[09:30]** and so suddenly the thing that you thought is going to take care of itself

**[09:32]** thought is going to take care of itself

**[09:32]** thought is going to take care of itself is not taking care of itself. uh that

**[09:34]** is not taking care of itself. uh that

**[09:34]** is not taking care of itself. uh that that cost are are really uh ballooning

**[09:36]** that cost are are really uh ballooning

**[09:36]** that cost are are really uh ballooning and and and enterprises think that maybe

**[09:39]** and and and enterprises think that maybe

**[09:39]** and and and enterprises think that maybe they can do better on the cost and unit

**[09:41]** they can do better on the cost and unit

**[09:41]** they can do better on the cost and unit economics. In order to show ROI, in

**[09:43]** economics. In order to show ROI, in

**[09:43]** economics. In order to show ROI, in order to show that the the solutions

**[09:44]** order to show that the the solutions

**[09:44]** order to show that the the solutions that they're pushing are are

**[09:46]** that they're pushing are are

**[09:46]** that they're pushing are are economically viable, they need to show

**[09:49]** economically viable, they need to show

**[09:49]** economically viable, they need to show uh they need to reduce uh the their cost

**[09:51]** uh they need to reduce uh the their cost

**[09:52]** uh they need to reduce uh the their cost somehow. And they're realizing that they

**[09:53]** somehow. And they're realizing that they

**[09:53]** somehow. And they're realizing that they can actually run these models and pay

**[09:55]** can actually run these models and pay

**[09:55]** can actually run these models and pay for the compute and have that be a lot

**[09:56]** for the compute and have that be a lot

**[09:56]** for the compute and have that be a lot cheaper than paying per token and and

**[09:58]** cheaper than paying per token and and

**[09:58]** cheaper than paying per token and and covering all the margins of someone else


### [10:00 - 11:00]

**[10:00]** covering all the margins of someone else

**[10:00]** covering all the margins of someone else and and really going from being a price

**[10:02]** and and really going from being a price

**[10:02]** and and really going from being a price taker to actually be the the the maker

**[10:05]** taker to actually be the the the maker

**[10:05]** taker to actually be the the the maker of the price and and being control of

**[10:07]** of the price and and being control of

**[10:07]** of the price and and being control of that. And then lastly, Destiny. This one

**[10:09]** that. And then lastly, Destiny. This one

**[10:09]** that. And then lastly, Destiny. This one is a bit vibby uh but but I'm hearing it

**[10:12]** is a bit vibby uh but but I'm hearing it

**[10:12]** is a bit vibby uh but but I'm hearing it more recently uh that um you know some

**[10:15]** more recently uh that um you know some

**[10:15]** more recently uh that um you know some CIO CTO saying if we the enterprise use

**[10:20]** CIO CTO saying if we the enterprise use

**[10:20]** CIO CTO saying if we the enterprise use uh just the frontier models and so do

**[10:23]** uh just the frontier models and so do

**[10:23]** uh just the frontier models and so do our competitors what is our advantage

**[10:25]** our competitors what is our advantage

**[10:25]** our competitors what is our advantage what is our alpha uh and uh and maybe we

**[10:28]** what is our alpha uh and uh and maybe we

**[10:28]** what is our alpha uh and uh and maybe we should bring in some of these things

**[10:29]** should bring in some of these things

**[10:29]** should bring in some of these things inhouse and to be able to even

**[10:31]** inhouse and to be able to even

**[10:31]** inhouse and to be able to even differentiate not just at the workflow

**[10:33]** differentiate not just at the workflow

**[10:33]** differentiate not just at the workflow and application level but also at the AI

**[10:37]** and application level but also at the AI

**[10:37]** and application level but also at the AI level. So now what if if those are the

**[10:40]** level. So now what if if those are the

**[10:40]** level. So now what if if those are the reasons why they want to adopt open

**[10:41]** reasons why they want to adopt open

**[10:42]** reasons why they want to adopt open source models and and iterate on those

**[10:43]** source models and and iterate on those

**[10:43]** source models and and iterate on those and build those uh and fine-tune those

**[10:45]** and build those uh and fine-tune those

**[10:45]** and build those uh and fine-tune those and distill those uh then what changes

**[10:49]** and distill those uh then what changes

**[10:49]** and distill those uh then what changes well what changes is that they go from

**[10:51]** well what changes is that they go from

**[10:51]** well what changes is that they go from super simple world that just call an API

**[10:53]** super simple world that just call an API

**[10:53]** super simple world that just call an API and run with it uh to now you need to

**[10:56]** and run with it uh to now you need to

**[10:56]** and run with it uh to now you need to build inference uh you need to build

**[10:58]** build inference uh you need to build

**[10:58]** build inference uh you need to build inference infra and you need to make

**[10:59]** inference infra and you need to make

**[10:59]** inference infra and you need to make sure that it scales well and you need to


### [11:00 - 12:00]

**[11:01]** sure that it scales well and you need to

**[11:01]** sure that it scales well and you need to make sure that you can move fast uh that

**[11:03]** make sure that you can move fast uh that

**[11:03]** make sure that you can move fast uh that that your engineers can actually uh

**[11:05]** that your engineers can actually uh

**[11:05]** that your engineers can actually uh deliver instead of having to you know

**[11:07]** deliver instead of having to you know

**[11:07]** deliver instead of having to you know hire a bunch to new types of people uh

**[11:09]** hire a bunch to new types of people uh

**[11:09]** hire a bunch to new types of people uh and then wait for them for a long time

**[11:11]** and then wait for them for a long time

**[11:11]** and then wait for them for a long time to actually build this uh build this

**[11:13]** to actually build this uh build this

**[11:13]** to actually build this uh build this infrastructure uh inhouse.

**[11:17]** infrastructure uh inhouse.

**[11:17]** infrastructure uh inhouse. So one thing that I hear quite a bit at

**[11:18]** So one thing that I hear quite a bit at

**[11:18]** So one thing that I hear quite a bit at this point is look I've I hear this from

**[11:21]** this point is look I've I hear this from

**[11:21]** this point is look I've I hear this from enterprises I hear this from startups

**[11:23]** enterprises I hear this from startups

**[11:23]** enterprises I hear this from startups too actually uh which is that look you

**[11:25]** too actually uh which is that look you

**[11:25]** too actually uh which is that look you know we've picked a model an open source

**[11:26]** know we've picked a model an open source

**[11:26]** know we've picked a model an open source model um we've heard of ELM or SG lang

**[11:30]** model um we've heard of ELM or SG lang

**[11:30]** model um we've heard of ELM or SG lang or TRTLM we have some GPUs in the case

**[11:32]** or TRTLM we have some GPUs in the case

**[11:32]** or TRTLM we have some GPUs in the case of enterprises in the data center in the

**[11:34]** of enterprises in the data center in the

**[11:34]** of enterprises in the data center in the case of startups it's in some cloud and

**[11:37]** case of startups it's in some cloud and

**[11:37]** case of startups it's in some cloud and you put these together and you get

**[11:38]** you put these together and you get

**[11:38]** you put these together and you get production inference and I know for a

**[11:41]** production inference and I know for a

**[11:41]** production inference and I know for a fact that this is not true uh I I wish

**[11:44]** fact that this is not true uh I I wish

**[11:44]** fact that this is not true uh I I wish it was true but I know for a fact that

**[11:45]** it was true but I know for a fact that

**[11:45]** it was true but I know for a fact that that this is not uh that that there's a

**[11:47]** that this is not uh that that there's a

**[11:47]** that this is not uh that that there's a lot more that goes into uh making uh

**[11:51]** lot more that goes into uh making uh

**[11:51]** lot more that goes into uh making uh inference especially mission critical

**[11:52]** inference especially mission critical

**[11:52]** inference especially mission critical inference work well uh in inside of your

**[11:55]** inference work well uh in inside of your

**[11:55]** inference work well uh in inside of your company.

**[11:57]** company.

**[11:57]** company. So so what are those? These are the


### [12:00 - 13:00]

**[12:00]** So so what are those? These are the

**[12:00]** So so what are those? These are the dragons. These are the dragons. So so

**[12:04]** dragons. These are the dragons. So so

**[12:04]** dragons. These are the dragons. So so one uh at the at the performance layer u

**[12:07]** one uh at the at the performance layer u

**[12:07]** one uh at the at the performance layer u you know we talked about you know

**[12:08]** you know we talked about you know

**[12:08]** you know we talked about you know situations where things are very latency

**[12:10]** situations where things are very latency

**[12:10]** situations where things are very latency sensitive. um the the way that you

**[12:12]** sensitive. um the the way that you

**[12:12]** sensitive. um the the way that you optimize models uh for for latency and

**[12:15]** optimize models uh for for latency and

**[12:16]** optimize models uh for for latency and is is actually quite quite involved uh

**[12:19]** is is actually quite quite involved uh

**[12:19]** is is actually quite quite involved uh both at the model level and at the

**[12:21]** both at the model level and at the

**[12:21]** both at the model level and at the infrastructure level. You have to do it

**[12:23]** infrastructure level. You have to do it

**[12:23]** infrastructure level. You have to do it you have to attack it at both levels. So

**[12:25]** you have to attack it at both levels. So

**[12:25]** you have to attack it at both levels. So as an example um you know for um uh at

**[12:28]** as an example um you know for um uh at

**[12:28]** as an example um you know for um uh at the model level it's like hey do you use

**[12:29]** the model level it's like hey do you use

**[12:29]** the model level it's like hey do you use speculative decoding uh and if so do you

**[12:31]** speculative decoding uh and if so do you

**[12:31]** speculative decoding uh and if so do you which which which route do you go do you

**[12:33]** which which which route do you go do you

**[12:33]** which which which route do you go do you go with a good draft model? Do you go

**[12:35]** go with a good draft model? Do you go

**[12:35]** go with a good draft model? Do you go with Medusa heads with with Eagle 3? Uh

**[12:37]** with Medusa heads with with Eagle 3? Uh

**[12:37]** with Medusa heads with with Eagle 3? Uh do you go with MTP? Um there's there's a

**[12:40]** do you go with MTP? Um there's there's a

**[12:40]** do you go with MTP? Um there's there's a lot and new techniques are coming out

**[12:41]** lot and new techniques are coming out

**[12:41]** lot and new techniques are coming out all the time. Like the the Eagle 3 paper

**[12:44]** all the time. Like the the Eagle 3 paper

**[12:44]** all the time. Like the the Eagle 3 paper came out like six months ago and it's

**[12:46]** came out like six months ago and it's

**[12:46]** came out like six months ago and it's like running in production and actually

**[12:47]** like running in production and actually

**[12:47]** like running in production and actually being very meaningful. Uh and so as an

**[12:50]** being very meaningful. Uh and so as an

**[12:50]** being very meaningful. Uh and so as an enterprise can can you hire the right

**[12:53]** enterprise can can you hire the right

**[12:53]** enterprise can can you hire the right folks to be able to be on top of the

**[12:54]** folks to be able to be on top of the

**[12:54]** folks to be able to be on top of the research because you don't this is these

**[12:56]** research because you don't this is these

**[12:56]** research because you don't this is these are not just you know switches that you

**[12:57]** are not just you know switches that you

**[12:57]** are not just you know switches that you flip in in SG lang or VLM and and and


### [13:00 - 14:00]

**[13:00]** flip in in SG lang or VLM and and and

**[13:00]** flip in in SG lang or VLM and and and get the get the results. Um uh some of

**[13:03]** get the get the results. Um uh some of

**[13:03]** get the get the results. Um uh some of these optimizations bleed out of the

**[13:05]** these optimizations bleed out of the

**[13:05]** these optimizations bleed out of the model level into the infrastructure

**[13:06]** model level into the infrastructure

**[13:06]** model level into the infrastructure level. Uh so as an example, if you want

**[13:10]** level. Uh so as an example, if you want

**[13:10]** level. Uh so as an example, if you want to uh be able to do uh uh prefix caching

**[13:14]** to uh be able to do uh uh prefix caching

**[13:14]** to uh be able to do uh uh prefix caching really well, if you want to be able to

**[13:15]** really well, if you want to be able to

**[13:15]** really well, if you want to be able to disagregate a serving really well, uh

**[13:17]** disagregate a serving really well, uh

**[13:17]** disagregate a serving really well, uh because that starts really mattering uh

**[13:21]** because that starts really mattering uh

**[13:21]** because that starts really mattering uh especially in in agentic use cases where

**[13:23]** especially in in agentic use cases where

**[13:23]** especially in in agentic use cases where like the prompts are massive but the

**[13:25]** like the prompts are massive but the

**[13:25]** like the prompts are massive but the prompts are somewhat similar from one to

**[13:27]** prompts are somewhat similar from one to

**[13:27]** prompts are somewhat similar from one to the other. uh ends up mattering a lot in

**[13:30]** the other. uh ends up mattering a lot in

**[13:30]** the other. uh ends up mattering a lot in in you hitting your you know time to

**[13:32]** in you hitting your you know time to

**[13:32]** in you hitting your you know time to first token and you hitting your P99 of

**[13:34]** first token and you hitting your P99 of

**[13:34]** first token and you hitting your P99 of that uh in a reliable way. Another thing

**[13:37]** that uh in a reliable way. Another thing

**[13:38]** that uh in a reliable way. Another thing on the infrastructure is especially if

**[13:40]** on the infrastructure is especially if

**[13:40]** on the infrastructure is especially if it's mission critical inference which

**[13:42]** it's mission critical inference which

**[13:42]** it's mission critical inference which more and more I see that that's the case

**[13:45]** more and more I see that that's the case

**[13:45]** more and more I see that that's the case how do you guarantee four nines and with

**[13:48]** how do you guarantee four nines and with

**[13:48]** how do you guarantee four nines and with with this with this formula does not

**[13:51]** with this with this formula does not

**[13:51]** with this with this formula does not guarantee you you know more than two

**[13:53]** guarantee you you know more than two

**[13:53]** guarantee you you know more than two nines uh and I and I saw this firsthand

**[13:56]** nines uh and I and I saw this firsthand

**[13:56]** nines uh and I and I saw this firsthand uh so how do you make sure that when the

**[13:59]** uh so how do you make sure that when the

**[13:59]** uh so how do you make sure that when the hardware fails underneath it uh you you


### [14:00 - 15:00]

**[14:01]** hardware fails underneath it uh you you

**[14:01]** hardware fails underneath it uh you you actually recover how do you make sure

**[14:03]** actually recover how do you make sure

**[14:03]** actually recover how do you make sure that you know when VLM crashes which it

**[14:05]** that you know when VLM crashes which it

**[14:05]** that you know when VLM crashes which it happens often I saw this firsthand like

**[14:07]** happens often I saw this firsthand like

**[14:07]** happens often I saw this firsthand like when Triton crashes often your tail

**[14:09]** when Triton crashes often your tail

**[14:09]** when Triton crashes often your tail latencies go through the roof while you

**[14:11]** latencies go through the roof while you

**[14:11]** latencies go through the roof while you wait for these things to come back. Uh

**[14:13]** wait for these things to come back. Uh

**[14:14]** wait for these things to come back. Uh and uh and and and and during that time

**[14:16]** and uh and and and and during that time

**[14:16]** and uh and and and and during that time like you your users are are are feeling

**[14:18]** like you your users are are are feeling

**[14:18]** like you your users are are are feeling that. Um how do you build uh against

**[14:22]** that. Um how do you build uh against

**[14:22]** that. Um how do you build uh against those and and make sure that you know

**[14:24]** those and and make sure that you know

**[14:24]** those and and make sure that you know you can still guarantee 49s and not be

**[14:26]** you can still guarantee 49s and not be

**[14:26]** you can still guarantee 49s and not be super overprovisioned and mess up all

**[14:28]** super overprovisioned and mess up all

**[14:28]** super overprovisioned and mess up all the unit economics that we talked about.

**[14:30]** the unit economics that we talked about.

**[14:30]** the unit economics that we talked about. Um when a big burst of traffic comes in,

**[14:33]** Um when a big burst of traffic comes in,

**[14:33]** Um when a big burst of traffic comes in, how do you make sure that you scale up

**[14:34]** how do you make sure that you scale up

**[14:34]** how do you make sure that you scale up fast? uh how do you make sure that uh

**[14:37]** fast? uh how do you make sure that uh

**[14:37]** fast? uh how do you make sure that uh you know I was talking to this massive

**[14:39]** you know I was talking to this massive

**[14:39]** you know I was talking to this massive enterprise like uh soft drink example

**[14:41]** enterprise like uh soft drink example

**[14:41]** enterprise like uh soft drink example where they're like yeah it takes us

**[14:43]** where they're like yeah it takes us

**[14:43]** where they're like yeah it takes us eight minutes when you want to bring up

**[14:44]** eight minutes when you want to bring up

**[14:44]** eight minutes when you want to bring up a new replica of the same model it takes

**[14:46]** a new replica of the same model it takes

**[14:46]** a new replica of the same model it takes eight minutes um and I believe that

**[14:48]** eight minutes um and I believe that

**[14:48]** eight minutes um and I believe that because that if you add up all the

**[14:49]** because that if you add up all the

**[14:49]** because that if you add up all the different things that it goes into doing

**[14:50]** different things that it goes into doing

**[14:50]** different things that it goes into doing that that is how long it takes but but

**[14:53]** that that is how long it takes but but

**[14:53]** that that is how long it takes but but that's not okay again your tail

**[14:54]** that's not okay again your tail

**[14:54]** that's not okay again your tail latencies go through the roof as soon as

**[14:55]** latencies go through the roof as soon as

**[14:55]** latencies go through the roof as soon as there's a big spike of traffic h how do

**[14:57]** there's a big spike of traffic h how do

**[14:57]** there's a big spike of traffic h how do you account for that and then there are

**[14:59]** you account for that and then there are

**[14:59]** you account for that and then there are other things around uh again like making


### [15:00 - 16:00]

**[15:01]** other things around uh again like making

**[15:02]** other things around uh again like making sure that your engineers move fast uh

**[15:04]** sure that your engineers move fast uh

**[15:04]** sure that your engineers move fast uh the tooling life

**[15:05]** the tooling life

**[15:05]** the tooling life life cycle management, the observability

**[15:08]** life cycle management, the observability

**[15:08]** life cycle management, the observability massive uh uh um uh iceberg which is

**[15:12]** massive uh uh um uh iceberg which is

**[15:12]** massive uh uh um uh iceberg which is like it's like oh yeah just put some

**[15:13]** like it's like oh yeah just put some

**[15:13]** like it's like oh yeah just put some logs and metrics and you realize there's

**[15:15]** logs and metrics and you realize there's

**[15:15]** logs and metrics and you realize there's a lot more to do underneath it. We just

**[15:18]** a lot more to do underneath it. We just

**[15:18]** a lot more to do underneath it. We just previous talk Michael talks about um and

**[15:20]** previous talk Michael talks about um and

**[15:20]** previous talk Michael talks about um and then lots of stuff around controls and

**[15:23]** then lots of stuff around controls and

**[15:23]** then lots of stuff around controls and um audits and uh things that enterprises

**[15:26]** um audits and uh things that enterprises

**[15:26]** um audits and uh things that enterprises actually care about. So so these are the

**[15:28]** actually care about. So so these are the

**[15:28]** actually care about. So so these are the these are the dragons. These are the

**[15:30]** these are the dragons. These are the

**[15:30]** these are the dragons. These are the dragons and these are the times that

**[15:31]** dragons and these are the times that

**[15:31]** dragons and these are the times that then enterprises h have a decision to

**[15:33]** then enterprises h have a decision to

**[15:33]** then enterprises h have a decision to make like once they once they get to

**[15:35]** make like once they once they get to

**[15:35]** make like once they once they get to this level either like I tell them or

**[15:38]** this level either like I tell them or

**[15:38]** this level either like I tell them or and they have to believe me or they

**[15:39]** and they have to believe me or they

**[15:39]** and they have to believe me or they don't and they go and build it and then

**[15:42]** don't and they go and build it and then

**[15:42]** don't and they go and build it and then then they they see some of these things

**[15:44]** then they they see some of these things

**[15:44]** then they they see some of these things that they have a decision which is build

**[15:46]** that they have a decision which is build

**[15:46]** that they have a decision which is build or buy and that's my job to then try to

**[15:49]** or buy and that's my job to then try to

**[15:49]** or buy and that's my job to then try to convince them that I think they should

**[15:50]** convince them that I think they should

**[15:50]** convince them that I think they should buy this uh this layer of infrastructure

**[15:54]** buy this uh this layer of infrastructure

**[15:54]** buy this uh this layer of infrastructure and platform uh as opposed to uh build

**[15:56]** and platform uh as opposed to uh build

**[15:56]** and platform uh as opposed to uh build it. Uh, and that's sometimes uh harder


### [16:00 - 17:00]

**[16:00]** it. Uh, and that's sometimes uh harder

**[16:00]** it. Uh, and that's sometimes uh harder harder than it seems.

**[16:03]** harder than it seems.

**[16:03]** harder than it seems. So, so I'm happy to talk more about

**[16:04]** So, so I'm happy to talk more about

**[16:04]** So, so I'm happy to talk more about these things. So, I'll be I'll be at our

**[16:06]** these things. So, I'll be I'll be at our

**[16:06]** these things. So, I'll be I'll be at our booth like two two topics I'd love to

**[16:07]** booth like two two topics I'd love to

**[16:08]** booth like two two topics I'd love to talk about if uh if you're interested.

**[16:10]** talk about if uh if you're interested.

**[16:10]** talk about if uh if you're interested. one, self-s servingly, if you're an

**[16:12]** one, self-s servingly, if you're an

**[16:12]** one, self-s servingly, if you're an enterprise and those problems resonate,

**[16:13]** enterprise and those problems resonate,

**[16:13]** enterprise and those problems resonate, I'd love to chat with you about. And

**[16:15]** I'd love to chat with you about. And

**[16:15]** I'd love to chat with you about. And two, less self-servingly, um, if you're

**[16:18]** two, less self-servingly, um, if you're

**[16:18]** two, less self-servingly, um, if you're a startup and you're trying to sell to

**[16:19]** a startup and you're trying to sell to

**[16:19]** a startup and you're trying to sell to enterprises, um, I'm happy to chat about

**[16:22]** enterprises, um, I'm happy to chat about

**[16:22]** enterprises, um, I'm happy to chat about all the right decisions that we made,

**[16:23]** all the right decisions that we made,

**[16:23]** all the right decisions that we made, the wrong decisions that we made along

**[16:25]** the wrong decisions that we made along

**[16:25]** the wrong decisions that we made along the way to to build something that then

**[16:28]** the way to to build something that then

**[16:28]** the way to to build something that then when it comes to selling to enterprises,

**[16:30]** when it comes to selling to enterprises,

**[16:30]** when it comes to selling to enterprises, when it comes to deploying it into their

**[16:31]** when it comes to deploying it into their

**[16:31]** when it comes to deploying it into their own clouds, uh, that that is actually

**[16:34]** own clouds, uh, that that is actually

**[16:34]** own clouds, uh, that that is actually possible, uh, and and and not a massive

**[16:37]** possible, uh, and and and not a massive

**[16:37]** possible, uh, and and and not a massive other set of dragons over there. And

**[16:38]** other set of dragons over there. And

**[16:38]** other set of dragons over there. And then last thing, we have a a happy hour.

**[16:41]** then last thing, we have a a happy hour.

**[16:41]** then last thing, we have a a happy hour. Uh we'd love to see you there. Thank

**[16:43]** Uh we'd love to see you there. Thank

**[16:43]** Uh we'd love to see you there. Thank you.


