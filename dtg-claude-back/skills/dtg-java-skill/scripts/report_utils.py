#!/usr/bin/env python3
"""
æŠ¥å‘Šç”Ÿæˆå·¥å…·å‡½æ•°
æä¾›æŠ¥å‘Šç”Ÿæˆçš„è¾…åŠ©åŠŸèƒ½å’Œå®ç”¨å·¥å…·
"""

import os
import json
import re
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
import subprocess


class ReportUtils:
    """æŠ¥å‘Šç”Ÿæˆå·¥å…·ç±»"""

    @staticmethod
    def find_latest_report(output_dir: str = "docs") -> Optional[str]:
        """æŸ¥æ‰¾æœ€æ–°çš„æŠ¥å‘Šæ–‡ä»¶"""
        try:
            output_path = Path(output_dir)
            if not output_path.exists():
                return None

            # æŸ¥æ‰¾æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶
            report_files = list(output_path.glob("review-*.md"))
            if not report_files:
                return None

            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè¿”å›æœ€æ–°çš„
            latest_file = max(report_files, key=lambda f: f.stat().st_mtime)
            return str(latest_file)

        except Exception:
            return None

    @staticmethod
    def get_report_history(output_dir: str = "docs", limit: int = 10) -> List[Dict[str, Any]]:
        """è·å–æŠ¥å‘Šå†å²è®°å½•"""
        try:
            output_path = Path(output_dir)
            if not output_path.exists():
                return []

            report_files = list(output_path.glob("review-*.md"))
            report_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)

            history = []
            for report_file in report_files[:limit]:
                stat = report_file.stat()
                history.append({
                    "path": str(report_file),
                    "name": report_file.name,
                    "size": stat.st_size,
                    "modified": datetime.fromtimestamp(stat.st_mtime),
                    "created": datetime.fromtimestamp(stat.st_ctime)
                })

            return history

        except Exception:
            return []

    @staticmethod
    def extract_report_summary(report_path: str) -> Dict[str, Any]:
        """ä»æŠ¥å‘Šæ–‡ä»¶ä¸­æå–æ‘˜è¦ä¿¡æ¯"""
        try:
            with open(report_path, 'r', encoding='utf-8') as f:
                content = f.read()

            summary = {}

            # æå–æ€»ä½“è¯„åˆ†
            score_match = re.search(r'æ€»ä½“è¯„åˆ†[ï¼š:]\s*([A-F])\s*\(([^)]+)\)', content)
            if score_match:
                summary["overall_grade"] = score_match.group(1)
                summary["overall_score"] = score_match.group(2)

            # æå–å¥åº·åº¦
            health_match = re.search(r'ä»£ç å¥åº·åº¦[ï¼š:]\s*(\d+)', content)
            if health_match:
                summary["health_score"] = int(health_match.group(1))

            # æå–é—®é¢˜æ•°é‡
            issue_stats = {}
            priority_patterns = [
                (r'ğŸ”´[^\\n]*?(\d+)\s*ä¸ª', 'high'),
                (r'ğŸŸ¡[^\\n]*?(\d+)\s*ä¸ª', 'medium'),
                (r'ğŸŸ¢[^\\n]*?(\d+)\s*ä¸ª', 'low')
            ]

            for pattern, priority in priority_patterns:
                matches = re.findall(pattern, content)
                if matches:
                    issue_stats[priority] = int(matches[0])

            summary["issue_counts"] = issue_stats

            # æå–æ–‡ä»¶æ•°é‡
            files_match = re.search(r'åˆ†ææ–‡ä»¶æ•°[ï¼š:]\s*(\d+)', content)
            if files_match:
                summary["files_analyzed"] = int(files_match.group(1))

            # æå–å®¡æŸ¥æ—¶é—´
            time_match = re.search(r'å®¡æŸ¥æ—¶é—´[ï¼š:]\s*([^\n]+)', content)
            if time_match:
                summary["review_time"] = time_match.group(1).strip()

            return summary

        except Exception:
            return {}

    @staticmethod
    def calculate_quality_trend(report_history: List[Dict[str, Any]]) -> Dict[str, Any]:
        """è®¡ç®—è´¨é‡è¶‹åŠ¿"""
        if len(report_history) < 2:
            return {
                "trend": "insufficient_data",
                "score_change": 0,
                "health_change": 0,
                "issue_change": 0
            }

        # æå–æœ€è¿‘çš„ä¸¤ä¸ªæŠ¥å‘Šçš„æ‘˜è¦
        current_summary = ReportUtils.extract_report_summary(report_history[0]["path"])
        previous_summary = ReportUtils.extract_report_summary(report_history[1]["path"])

        # è®¡ç®—å˜åŒ–
        trend_data = {
            "trend": "stable",
            "score_change": 0,
            "health_change": 0,
            "issue_change": 0
        }

        # è®¡ç®—è¯„åˆ†å˜åŒ–
        current_score = current_summary.get("overall_score", "0")
        previous_score = previous_summary.get("overall_score", "0")

        try:
            current_num = float(re.findall(r'\\d+\\.?\\d*', current_score)[0])
            previous_num = float(re.findall(r'\\d+\\.?\\d*', previous_score)[0])
            trend_data["score_change"] = current_num - previous_num
        except:
            pass

        # è®¡ç®—å¥åº·åº¦å˜åŒ–
        current_health = current_summary.get("health_score", 0)
        previous_health = previous_summary.get("health_score", 0)
        trend_data["health_change"] = current_health - previous_health

        # è®¡ç®—é—®é¢˜æ•°é‡å˜åŒ–
        current_issues = sum(current_summary.get("issue_counts", {}).values())
        previous_issues = sum(previous_summary.get("issue_counts", {}).values())
        trend_data["issue_change"] = current_issues - previous_issues

        # ç¡®å®šè¶‹åŠ¿
        if trend_data["score_change"] > 5 or trend_data["health_change"] > 5:
            trend_data["trend"] = "improving"
        elif trend_data["score_change"] < -5 or trend_data["health_change"] < -5:
            trend_data["trend"] = "declining"
        else:
            trend_data["trend"] = "stable"

        return trend_data

    @staticmethod
    def clean_old_reports(output_dir: str = "docs", keep_count: int = 20) -> int:
        """æ¸…ç†æ—§æŠ¥å‘Šæ–‡ä»¶ï¼Œä¿ç•™æŒ‡å®šæ•°é‡çš„æœ€æ–°æŠ¥å‘Š"""
        try:
            output_path = Path(output_dir)
            if not output_path.exists():
                return 0

            report_files = list(output_path.glob("review-*.md"))
            if len(report_files) <= keep_count:
                return 0

            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åº
            report_files.sort(key=lambda f: f.stat().st_mtime, reverse=True)

            # åˆ é™¤è¶…å‡ºä¿ç•™æ•°é‡çš„æ–‡ä»¶
            files_to_delete = report_files[keep_count:]
            deleted_count = 0

            for file_path in files_to_delete:
                try:
                    file_path.unlink()
                    deleted_count += 1
                except Exception:
                    pass

            return deleted_count

        except Exception:
            return 0

    @staticmethod
    def get_report_statistics(output_dir: str = "docs") -> Dict[str, Any]:
        """è·å–æŠ¥å‘Šç»Ÿè®¡ä¿¡æ¯"""
        try:
            output_path = Path(output_dir)
            if not output_path.exists():
                return {
                    "total_reports": 0,
                    "total_size": 0,
                    "latest_report": None,
                    "oldest_report": None
                }

            report_files = list(output_path.glob("review-*.md"))

            if not report_files:
                return {
                    "total_reports": 0,
                    "total_size": 0,
                    "latest_report": None,
                    "oldest_report": None
                }

            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            total_size = sum(f.stat().st_size for f in report_files)
            latest_file = max(report_files, key=lambda f: f.stat().st_mtime)
            oldest_file = min(report_files, key=lambda f: f.stat().st_mtime)

            return {
                "total_reports": len(report_files),
                "total_size": total_size,
                "latest_report": {
                    "path": str(latest_file),
                    "name": latest_file.name,
                    "modified": datetime.fromtimestamp(latest_file.stat().st_mtime)
                },
                "oldest_report": {
                    "path": str(oldest_file),
                    "name": oldest_file.name,
                    "modified": datetime.fromtimestamp(oldest_file.stat().st_mtime)
                }
            }

        except Exception:
            return {
                "total_reports": 0,
                "total_size": 0,
                "latest_report": None,
                "oldest_report": None
            }

    @staticmethod
    def validate_report_file(report_path: str) -> Dict[str, Any]:
        """éªŒè¯æŠ¥å‘Šæ–‡ä»¶çš„å®Œæ•´æ€§"""
        try:
            report_path = Path(report_path)
            if not report_path.exists():
                return {
                    "valid": False,
                    "error": "æ–‡ä»¶ä¸å­˜åœ¨"
                }

            if not report_path.is_file():
                return {
                    "valid": False,
                    "error": "è·¯å¾„ä¸æ˜¯æ–‡ä»¶"
                }

            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            if report_path.stat().st_size == 0:
                return {
                    "valid": False,
                    "error": "æ–‡ä»¶ä¸ºç©º"
                }

            # æ£€æŸ¥æ–‡ä»¶å†…å®¹
            with open(report_path, 'r', encoding='utf-8') as f:
                content = f.read()

            if not content.strip():
                return {
                    "valid": False,
                    "error": "æ–‡ä»¶å†…å®¹ä¸ºç©º"
                }

            # æ£€æŸ¥æ˜¯å¦æ˜¯MarkdownæŠ¥å‘Š
            required_headers = [
                "# ğŸ“‹ AI æ™ºèƒ½ä»£ç å®¡æŸ¥æŠ¥å‘Š",
                "## ğŸ“Š å®¡æŸ¥æ¦‚è¿°",
                "## ğŸ¯ æ™ºèƒ½è´¨é‡è¯„ä¼°"
            ]

            missing_headers = []
            for header in required_headers:
                if header not in content:
                    missing_headers.append(header)

            if missing_headers:
                return {
                    "valid": False,
                    "error": f"ç¼ºå°‘å¿…è¦çš„æ ‡é¢˜: {', '.join(missing_headers)}"
                }

            # æå–åŸºæœ¬ä¿¡æ¯
            summary = ReportUtils.extract_report_summary(str(report_path))

            return {
                "valid": True,
                "summary": summary,
                "file_size": report_path.stat().st_size,
                "line_count": len(content.split('\n'))
            }

        except Exception as e:
            return {
                "valid": False,
                "error": f"éªŒè¯å¤±è´¥: {str(e)}"
            }

    @staticmethod
    def open_report_in_editor(report_path: str, editor: Optional[str] = None) -> bool:
        """åœ¨ç¼–è¾‘å™¨ä¸­æ‰“å¼€æŠ¥å‘Šæ–‡ä»¶"""
        try:
            # ç¡®å®šç¼–è¾‘å™¨
            if editor:
                cmd = [editor, report_path]
            else:
                # å°è¯•ä½¿ç”¨ç³»ç»Ÿé»˜è®¤ç¼–è¾‘å™¨
                editor = os.environ.get('EDITOR')
                if editor:
                    cmd = [editor, report_path]
                else:
                    # æ ¹æ®æ“ä½œç³»ç»Ÿé€‰æ‹©é»˜è®¤ç¼–è¾‘å™¨
                    import platform
                    if platform.system() == 'Darwin':  # macOS
                        cmd = ['open', '-a', 'TextEdit', report_path]
                    elif platform.system() == 'Windows':
                        cmd = ['notepad', report_path]
                    else:  # Linux
                        cmd = ['xdg-open', report_path]

            # æ‰§è¡Œå‘½ä»¤
            subprocess.run(cmd, check=True)
            return True

        except Exception:
            return False

    @staticmethod
    def generate_report_index(output_dir: str = "docs") -> str:
        """ç”ŸæˆæŠ¥å‘Šç´¢å¼•æ–‡ä»¶"""
        try:
            output_path = Path(output_dir)
            output_path.mkdir(exist_ok=True)

            # è·å–æŠ¥å‘Šå†å²
            history = ReportUtils.get_report_history(output_dir)
            statistics = ReportUtils.get_report_statistics(output_dir)

            # ç”Ÿæˆç´¢å¼•å†…å®¹
            index_content = f"""# ä»£ç å®¡æŸ¥æŠ¥å‘Šç´¢å¼•

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

- **æ€»æŠ¥å‘Šæ•°**: {statistics['total_reports']}
- **æ€»å¤§å°**: {ReportUtils._format_size(statistics['total_size'])}
- **æœ€æ–°æŠ¥å‘Š**: {statistics['latest_report']['name'] if statistics['latest_report'] else 'æ— '}
- **æœ€æ—©æŠ¥å‘Š**: {statistics['oldest_report']['name'] if statistics['oldest_report'] else 'æ— '}

## ğŸ“‹ æŠ¥å‘Šå†å²

| åºå· | æŠ¥å‘Šåç§° | ç”Ÿæˆæ—¶é—´ | æ–‡ä»¶å¤§å° | æ‘˜è¦ |
|------|----------|----------|----------|------|
"""

            for i, report in enumerate(history, 1):
                summary = ReportUtils.extract_report_summary(report["path"])
                grade = summary.get("overall_grade", "N/A")
                health = summary.get("health_score", "N/A")
                issues = sum(summary.get("issue_counts", {}).values())

                index_content += f"| {i} | [{report['name']}]({report['name']}) | {report['modified'].strftime('%Y-%m-%d %H:%M')} | {ReportUtils._format_size(report['size'])} | è¯„åˆ†: {grade} | å¥åº·åº¦: {health} | é—®é¢˜æ•°: {issues} |\n"

            index_content += f"""

---

*ç´¢å¼•ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""

            # å†™å…¥ç´¢å¼•æ–‡ä»¶
            index_path = output_path / "REPORT_INDEX.md"
            with open(index_path, 'w', encoding='utf-8') as f:
                f.write(index_content)

            return str(index_path)

        except Exception:
            return ""

    @staticmethod
    def _format_size(size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f} MB"


def main():
    """å‘½ä»¤è¡Œå·¥å…·å…¥å£"""
    import argparse

    parser = argparse.ArgumentParser(description="æŠ¥å‘Šç”Ÿæˆå·¥å…·")
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # listå‘½ä»¤
    list_parser = subparsers.add_parser('list', help='åˆ—å‡ºæŠ¥å‘Šå†å²')
    list_parser.add_argument('--output-dir', '-o', default='docs', help='è¾“å‡ºç›®å½•')
    list_parser.add_argument('--limit', '-l', type=int, default=10, help='æ˜¾ç¤ºæ•°é‡é™åˆ¶')

    # latestå‘½ä»¤
    latest_parser = subparsers.add_parser('latest', help='æ˜¾ç¤ºæœ€æ–°æŠ¥å‘Šè·¯å¾„')
    latest_parser.add_argument('--output-dir', '-o', default='docs', help='è¾“å‡ºç›®å½•')

    # statså‘½ä»¤
    stats_parser = subparsers.add_parser('stats', help='æ˜¾ç¤ºæŠ¥å‘Šç»Ÿè®¡ä¿¡æ¯')
    stats_parser.add_argument('--output-dir', '-o', default='docs', help='è¾“å‡ºç›®å½•')

    # cleanå‘½ä»¤
    clean_parser = subparsers.add_parser('clean', help='æ¸…ç†æ—§æŠ¥å‘Š')
    clean_parser.add_argument('--output-dir', '-o', default='docs', help='è¾“å‡ºç›®å½•')
    clean_parser.add_argument('--keep', '-k', type=int, default=20, help='ä¿ç•™æ•°é‡')

    # validateå‘½ä»¤
    validate_parser = subparsers.add_parser('validate', help='éªŒè¯æŠ¥å‘Šæ–‡ä»¶')
    validate_parser.add_argument('report_path', help='æŠ¥å‘Šæ–‡ä»¶è·¯å¾„')

    # indexå‘½ä»¤
    index_parser = subparsers.add_parser('index', help='ç”ŸæˆæŠ¥å‘Šç´¢å¼•')
    index_parser.add_argument('--output-dir', '-o', default='docs', help='è¾“å‡ºç›®å½•')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    if args.command == 'list':
        history = ReportUtils.get_report_history(args.output_dir, args.limit)
        if history:
            print(f"æŠ¥å‘Šå†å² (æœ€è¿‘{len(history)}ä¸ª):")
            for i, report in enumerate(history, 1):
                summary = ReportUtils.extract_report_summary(report["path"])
                grade = summary.get("overall_grade", "N/A")
                health = summary.get("health_score", "N/A")
                print(f"{i:2d}. {report['name']} ({report['modified'].strftime('%Y-%m-%d %H:%M')}) - è¯„åˆ†:{grade} å¥åº·åº¦:{health}")
        else:
            print("æœªæ‰¾åˆ°æŠ¥å‘Šæ–‡ä»¶")

    elif args.command == 'latest':
        latest = ReportUtils.find_latest_report(args.output_dir)
        if latest:
            print(f"æœ€æ–°æŠ¥å‘Š: {latest}")
        else:
            print("æœªæ‰¾åˆ°æŠ¥å‘Šæ–‡ä»¶")

    elif args.command == 'stats':
        stats = ReportUtils.get_report_statistics(args.output_dir)
        print(f"æŠ¥å‘Šç»Ÿè®¡ä¿¡æ¯:")
        print(f"  æ€»æŠ¥å‘Šæ•°: {stats['total_reports']}")
        print(f"  æ€»å¤§å°: {ReportUtils._format_size(stats['total_size'])}")
        if stats['latest_report']:
            print(f"  æœ€æ–°æŠ¥å‘Š: {stats['latest_report']['name']} ({stats['latest_report']['modified'].strftime('%Y-%m-%d %H:%M')})")

    elif args.command == 'clean':
        deleted = ReportUtils.clean_old_reports(args.output_dir, args.keep)
        print(f"å·²æ¸…ç† {deleted} ä¸ªæ—§æŠ¥å‘Šæ–‡ä»¶")

    elif args.command == 'validate':
        result = ReportUtils.validate_report_file(args.report_path)
        if result['valid']:
            print("âœ… æŠ¥å‘Šæ–‡ä»¶æœ‰æ•ˆ")
            if 'summary' in result:
                summary = result['summary']
                print(f"  è¯„åˆ†: {summary.get('overall_grade', 'N/A')}")
                print(f"  å¥åº·åº¦: {summary.get('health_score', 'N/A')}")
                print(f"  æ–‡ä»¶å¤§å°: {ReportUtils._format_size(result['file_size'])}")
        else:
            print(f"âŒ æŠ¥å‘Šæ–‡ä»¶æ— æ•ˆ: {result['error']}")

    elif args.command == 'index':
        index_path = ReportUtils.generate_report_index(args.output_dir)
        if index_path:
            print(f"âœ… æŠ¥å‘Šç´¢å¼•å·²ç”Ÿæˆ: {index_path}")
        else:
            print("âŒ ç”ŸæˆæŠ¥å‘Šç´¢å¼•å¤±è´¥")


if __name__ == "__main__":
    main()