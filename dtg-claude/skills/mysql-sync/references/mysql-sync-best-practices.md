# MySQL 数据同步最佳实践

## 使用场景

dtg-mysql-sync 主要用于以下场景：

- **开发环境数据同步**: 从生产/测试环境同步数据到本地开发环境
- **多节点数据复制**: 在 MySQL 主从架构或集群环境中复制表数据
- **数据迁移**: 在不同 MySQL 实例间迁移表数据
- **测试数据准备**: 快速复制测试数据到不同环境

## 数据库连接

### 默认配置

脚本内置了 xxpay 项目的默认数据库连接：

| 节点 | Host | Port | Database | User |
|------|------|------|----------|------|
| Node 1 (源) | 127.0.0.1 | 3307 | xxpay | dtgMysqlTest |
| Node 2 (目标) | 127.0.0.1 | 3306 | xxpay | root |

### 自定义连接

可以通过命令行参数覆盖默认配置：

```bash
python3 mysql_sync.py \
  --table pay_order \
  --source-host 192.168.1.100 \
  --source-port 3307 \
  --target-host 192.168.1.101 \
  --target-port 3306
```

## 同步流程

1. **连接验证**: 验证源数据库和目标数据库连接
2. **表存在检查**: 确保源表和目标表都存在
3. **结构分析**: 读取表的列定义
4. **数据统计**: 显示源表和目标表的行数
5. **清除目标表**: 删除目标表的所有数据（如有）
6. **批量复制**: 从源表分批读取并插入到目标表
7. **事务提交**: 确保数据一致性
8. **结果报告**: 显示同步统计信息

## 安全特性

### 事务安全

- 源数据读取：只读操作，不影响源表
- 目标表操作：使用事务，失败时自动回滚
- 外键处理：自动禁用/启用外键检查

### 错误处理

- 连接失败：明确的错误提示
- 表不存在：清晰的错误信息
- 数据类型不匹配：PyMySQL 自动处理
- 权限不足：详细的错误提示

## 性能优化

### 批量插入

脚本使用批量插入优化（默认每批 1000 行）：

```python
BATCH_SIZE = 1000
```

可以根据网络延迟和表结构调整此值。

### 外键约束

自动禁用外键检查以提高性能：

```sql
SET FOREIGN_KEY_CHECKS = 0;
-- 执行数据操作
SET FOREIGN_KEY_CHECKS = 1;
```

## 常见问题

### Q: 如何同步多个表？

A: 目前脚本一次同步一个表，可以通过 shell 循环：

```bash
for table in pay_order pay_channel pay_record; do
  python3 mysql_sync.py --table $table
done
```

### Q: 大表同步会很慢吗？

A: 脚本使用批量操作和进度显示，但仍受网络和表大小影响。建议：
- 在低峰期执行
- 考虑使用 MySQL 主从复制作为长期方案

### Q: 如何处理自增 ID？

A: 脚本直接复制数据，自增 ID 会保持原值。目标表的自增值不会自动更新，但不会影响数据插入。

### Q: 同步失败会怎样？

A: 脚本使用事务，失败时会自动回滚，目标表保持原状态。

## 扩展建议

未来可以考虑的功能：

1. **多表同步**: 支持一次同步多个表
2. **条件过滤**: 支持 WHERE 条件过滤数据
3. **增量同步**: 基于时间戳的增量复制
4. **并发同步**: 多线程并发复制
5. **配置文件**: 支持从配置文件读取连接信息

## 相关资源

- [MySQL 8 官方文档](https://dev.mysql.com/doc/refman/8.0/en/)
- [PyMySQL 文档](https://pymysql.readthedocs.io/)
- [Rich 终端库](https://rich.readthedocs.io/)
