#!/usr/bin/env python3
"""
æ™ºèƒ½ä»£ç å®¡æŸ¥æŠ¥å‘Šå¼•æ“
è´Ÿè´£å°†èšåˆçš„å®¡æŸ¥æ•°æ®æ¸²æŸ“ä¸ºè¯¦ç»†çš„MarkdownæŠ¥å‘Š
"""

import os
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional
from jinja2 import Environment, FileSystemLoader, Template
import yaml

from data_aggregator import ReviewDataAggregator


class ReportEngine:
    """ä»£ç å®¡æŸ¥æŠ¥å‘Šå¼•æ“"""

    def __init__(self, template_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–æŠ¥å‘Šå¼•æ“

        Args:
            template_dir: æ¨¡æ¿ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä½¿ç”¨å½“å‰ç›®å½•ä¸‹çš„templates
        """
        if template_dir is None:
            # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•çš„templateså­ç›®å½•
            current_dir = Path(__file__).parent
            template_dir = current_dir / "templates"

        self.template_dir = Path(template_dir)
        self.template_dir.mkdir(exist_ok=True)

        # åˆå§‹åŒ–Jinja2ç¯å¢ƒ
        self.jinja_env = Environment(
            loader=FileSystemLoader(str(self.template_dir)),
            autoescape=False,
            trim_blocks=True,
            lstrip_blocks=True
        )

        # æ³¨å†Œè‡ªå®šä¹‰è¿‡æ»¤å™¨
        self._register_custom_filters()

        self.aggregator = ReviewDataAggregator()

    def _register_custom_filters(self):
        """æ³¨å†Œè‡ªå®šä¹‰Jinja2è¿‡æ»¤å™¨"""

        def priority_emoji(priority: str) -> str:
            """ä¼˜å…ˆçº§è½¬è¡¨æƒ…ç¬¦å·"""
            emoji_map = {
                "high": "ğŸ”´",
                "medium": "ğŸŸ¡",
                "low": "ğŸŸ¢"
            }
            return emoji_map.get(priority, "âšª")

        def grade_color(grade: str) -> str:
            """ç­‰çº§è½¬é¢œè‰²"""
            color_map = {
                "A": "ğŸŸ¢",
                "B": "ğŸŸ¡",
                "C": "ğŸŸ ",
                "D": "ğŸ”´",
                "F": "âš«"
            }
            return color_map.get(grade, "âšª")

        def format_datetime(timestamp: str, format_str: str = "%Y-%m-%d %H:%M:%S") -> str:
            """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
            try:
                dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                return dt.strftime(format_str)
            except:
                return timestamp

        def risk_level_emoji(risk_level: str) -> str:
            """é£é™©ç­‰çº§è½¬è¡¨æƒ…ç¬¦å·"""
            emoji_map = {
                "high": "ğŸš¨",
                "medium": "âš ï¸",
                "low": "âœ…"
            }
            return emoji_map.get(risk_level, "â“")

        def format_file_size(size_bytes: int) -> str:
            """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
            if size_bytes < 1024:
                return f"{size_bytes} B"
            elif size_bytes < 1024 * 1024:
                return f"{size_bytes / 1024:.1f} KB"
            else:
                return f"{size_bytes / (1024 * 1024):.1f} MB"

        # æ³¨å†Œè¿‡æ»¤å™¨
        self.jinja_env.filters['priority_emoji'] = priority_emoji
        self.jinja_env.filters['grade_color'] = grade_color
        self.jinja_env.filters['format_datetime'] = format_datetime
        self.jinja_env.filters['risk_level_emoji'] = risk_level_emoji
        self.jinja_env.filters['format_file_size'] = format_file_size

    def generate_report(self,
                       review_data: Dict[str, Any],
                       template_name: str = "comprehensive_review.md.j2",
                       output_dir: str = "docs",
                       filename: Optional[str] = None) -> str:
        """
        ç”Ÿæˆä»£ç å®¡æŸ¥æŠ¥å‘Š

        Args:
            review_data: èšåˆçš„å®¡æŸ¥æ•°æ®
            template_name: æ¨¡æ¿æ–‡ä»¶å
            output_dir: è¾“å‡ºç›®å½•
            filename: è‡ªå®šä¹‰æ–‡ä»¶åï¼ˆä¸åŒ…å«æ‰©å±•åï¼‰

        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            # åŠ è½½æ¨¡æ¿
            template = self.jinja_env.get_template(template_name)

            # å‡†å¤‡æ¨¡æ¿æ•°æ®
            template_data = self._prepare_template_data(review_data)

            # æ¸²æŸ“æŠ¥å‘Š
            report_content = template.render(**template_data)

            # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
            if filename is None:
                timestamp = datetime.now().strftime("%Y-%m-%d-%H-%M-%S")
                filename = f"review-{timestamp}"

            output_dir = Path(output_dir)
            output_dir.mkdir(exist_ok=True)

            report_path = output_dir / f"{filename}.md"

            # å†™å…¥æ–‡ä»¶
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)

            return str(report_path)

        except Exception as e:
            raise RuntimeError(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")

    def _prepare_template_data(self, review_data: Dict[str, Any]) -> Dict[str, Any]:
        """å‡†å¤‡æ¨¡æ¿æ•°æ®"""

        # æ·»åŠ è®¡ç®—å­—æ®µ
        template_data = review_data.copy()

        # æ·»åŠ ç”Ÿæˆæ—¶é—´
        template_data["generation_time"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        # æ·»åŠ æ’ä»¶ç‰ˆæœ¬ä¿¡æ¯
        template_data["plugin_version"] = "1.0.0"

        # æ·»åŠ AIæ¨¡å‹ä¿¡æ¯
        template_data["ai_model"] = "Claude Sonnet 4.5"

        # è®¡ç®—é—®é¢˜ç»Ÿè®¡
        issues = review_data.get("issues", [])
        template_data["issue_statistics"] = self._calculate_issue_statistics(issues)

        # ç”Ÿæˆæ‰§è¡Œæ‘˜è¦
        template_data["executive_summary"] = self._generate_executive_summary(review_data)

        # ç”Ÿæˆä¸‹ä¸€æ­¥è¡ŒåŠ¨è®¡åˆ’
        template_data["action_plan"] = self._generate_action_plan(review_data)

        return template_data

    def _calculate_issue_statistics(self, issues: list) -> Dict[str, Any]:
        """è®¡ç®—é—®é¢˜ç»Ÿè®¡ä¿¡æ¯"""
        if not issues:
            return {
                "total": 0,
                "by_priority": {"high": 0, "medium": 0, "low": 0},
                "by_category": {},
                "by_source": {}
            }

        stats = {
            "total": len(issues),
            "by_priority": {"high": 0, "medium": 0, "low": 0},
            "by_category": {},
            "by_source": {}
        }

        for issue in issues:
            # æŒ‰ä¼˜å…ˆçº§ç»Ÿè®¡
            priority = issue.get("priority", "medium")
            stats["by_priority"][priority] = stats["by_priority"].get(priority, 0) + 1

            # æŒ‰ç±»åˆ«ç»Ÿè®¡
            category = issue.get("category", "general")
            stats["by_category"][category] = stats["by_category"].get(category, 0) + 1

            # æŒ‰æ¥æºç»Ÿè®¡
            source = issue.get("source", "unknown")
            stats["by_source"][source] = stats["by_source"].get(source, 0) + 1

        return stats

    def _generate_executive_summary(self, review_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ‰§è¡Œæ‘˜è¦"""
        quality_metrics = review_data.get("quality_metrics", {})
        review_summary = review_data.get("review_summary", {})
        issues = review_data.get("issues", [])

        summary = {
            "overall_assessment": self._get_overall_assessment(quality_metrics),
            "key_findings": self._extract_key_findings(issues, quality_metrics),
            "critical_issues": [i for i in issues if i.get("priority") == "high"][:3],  # æœ€å¤š3ä¸ªå…³é”®é—®é¢˜
            "quality_trend": "stable",  # å¯ä»¥åŸºäºå†å²æ•°æ®è®¡ç®—
            "recommendations_priority": "high" if len([i for i in issues if i.get("priority") == "high"]) > 2 else "medium"
        }

        return summary

    def _get_overall_assessment(self, quality_metrics: Dict[str, Any]) -> str:
        """è·å–æ€»ä½“è¯„ä¼°"""
        overall_score = quality_metrics.get("overall_score", 70)
        overall_grade = quality_metrics.get("overall_grade", "C")

        if overall_score >= 85:
            return f"ä¼˜ç§€ (Açº§, {overall_score}åˆ†) - ä»£ç è´¨é‡å¾ˆé«˜ï¼Œç¬¦åˆä¼ä¸šçº§æ ‡å‡†"
        elif overall_score >= 75:
            return f"è‰¯å¥½ ({overall_grade}çº§, {overall_score}åˆ†) - ä»£ç è´¨é‡è¾ƒå¥½ï¼Œæœ‰å°‘é‡æ”¹è¿›ç©ºé—´"
        elif overall_score >= 65:
            return f"ä¸€èˆ¬ ({overall_grade}çº§, {overall_score}åˆ†) - ä»£ç è´¨é‡ä¸­ç­‰ï¼Œéœ€è¦ä¸€äº›æ”¹è¿›"
        elif overall_score >= 50:
            return f"è¾ƒå·® ({overall_grade}çº§, {overall_score}åˆ†) - ä»£ç è´¨é‡è¾ƒä½ï¼Œéœ€è¦é‡ç‚¹æ”¹è¿›"
        else:
            return f"å·® ({overall_grade}çº§, {overall_score}åˆ†) - ä»£ç è´¨é‡å¾ˆå·®ï¼Œéœ€è¦ç«‹å³é‡æ„"

    def _extract_key_findings(self, issues: list, quality_metrics: Dict[str, Any]) -> list:
        """æå–å…³é”®å‘ç°"""
        findings = []

        # åŸºäºé—®é¢˜æ•°é‡çš„å‘ç°
        high_count = len([i for i in issues if i.get("priority") == "high"])
        if high_count > 0:
            findings.append(f"å‘ç° {high_count} ä¸ªé«˜ä¼˜å…ˆçº§é—®é¢˜éœ€è¦ç«‹å³å¤„ç†")

        # åŸºäºè¯„åˆ†çš„å‘ç°
        health_score = quality_metrics.get("health_score", 70)
        if health_score < 60:
            findings.append(f"ä»£ç å¥åº·åº¦è¾ƒä½ ({health_score}åˆ†)ï¼Œå»ºè®®è¿›è¡Œå…¨é¢é‡æ„")
        elif health_score < 80:
            findings.append(f"ä»£ç å¥åº·åº¦ä¸­ç­‰ ({health_score}åˆ†)ï¼Œæœ‰æ”¹è¿›ç©ºé—´")

        # åŸºäºæ¶æ„çš„å‘ç°
        architecture_score = quality_metrics.get("architecture_score", 70)
        if architecture_score < 70:
            findings.append("æ¶æ„è®¾è®¡å­˜åœ¨ä¼˜åŒ–ç©ºé—´")

        # åŸºäºæ€§èƒ½é£é™©çš„å‘ç°
        performance_risk = quality_metrics.get("performance_risk", "medium")
        if performance_risk == "high":
            findings.append("å­˜åœ¨è¾ƒé«˜çš„æ€§èƒ½é£é™©")

        return findings

    def _generate_action_plan(self, review_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆè¡ŒåŠ¨è®¡åˆ’"""
        issues = review_data.get("issues", [])
        quality_metrics = review_data.get("quality_metrics", {})

        # æŒ‰ä¼˜å…ˆçº§åˆ†ç»„é—®é¢˜
        high_issues = [i for i in issues if i.get("priority") == "high"]
        medium_issues = [i for i in issues if i.get("priority") == "medium"]
        low_issues = [i for i in issues if i.get("priority") == "low"]

        # å³æ—¶è¡ŒåŠ¨é¡¹ (1-2å‘¨)
        immediate_actions = []
        for issue in high_issues[:5]:  # æœ€å¤š5ä¸ªå³æ—¶è¡ŒåŠ¨é¡¹
            immediate_actions.append({
                "action": f"ä¿®å¤é—®é¢˜: {issue.get('description', 'æœªçŸ¥é—®é¢˜')}",
                "location": issue.get('location', 'æœªæŒ‡å®š'),
                "estimated_time": "2-3å¤©" if "å¤æ‚" in issue.get('description', '') else "1å¤©",
                "priority": "é«˜"
            })

        # çŸ­æœŸç›®æ ‡ (1ä¸ªæœˆ)
        short_term_goals = []
        if medium_issues:
            short_term_goals.append(f"å¤„ç† {len(medium_issues)} ä¸ªä¸­ä¼˜å…ˆçº§é—®é¢˜")

        if quality_metrics.get("health_score", 70) < 80:
            short_term_goals.append("æå‡ä»£ç å¥åº·åº¦è‡³80åˆ†ä»¥ä¸Š")

        short_term_goals.append("å®æ–½æ¶æ„ä¼˜åŒ–å»ºè®®")
        short_term_goals.append("å®Œå–„å•å…ƒæµ‹è¯•è¦†ç›–ç‡")

        # é•¿æœŸæ”¹è¿› (3ä¸ªæœˆ+)
        long_term_improvements = [
            "å»ºç«‹ä»£ç è´¨é‡ç›‘æ§ä½“ç³»",
            "å®æ–½æŒç»­é›†æˆå’Œä»£ç è´¨é‡é—¨ç¦",
            "å®šæœŸè¿›è¡Œæ¶æ„è¯„å®¡å’Œé‡æ„",
            "å›¢é˜ŸåŸ¹è®­å’Œæœ€ä½³å®è·µæ¨å¹¿",
            "å¼•å…¥è‡ªåŠ¨åŒ–ä»£ç è´¨é‡æ£€æŸ¥å·¥å…·"
        ]

        return {
            "immediate_actions": immediate_actions,
            "short_term_goals": short_term_goals,
            "long_term_improvements": long_term_improvements
        }

    def generate_from_agent_outputs(self,
                                  code_reviewer_output: str,
                                  architecture_analyzer_output: str = "",
                                  intelligent_diagnoser_output: str = "",
                                  quality_gate_output: str = "",
                                  output_dir: str = "docs") -> str:
        """
        ä»ä»£ç†è¾“å‡ºç”ŸæˆæŠ¥å‘Šçš„ä¾¿æ·æ–¹æ³•

        Args:
            code_reviewer_output: code-reviewerä»£ç†çš„è¾“å‡º
            architecture_analyzer_output: architecture-analyzerä»£ç†çš„è¾“å‡º
            intelligent_diagnoser_output: intelligent-diagnoserä»£ç†çš„è¾“å‡º
            quality_gate_output: è´¨é‡é—¨ç¦çš„è¾“å‡º
            output_dir: è¾“å‡ºç›®å½•

        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        # èšåˆæ•°æ®
        review_data = self.aggregator.aggregate_review_data(
            code_reviewer_output=code_reviewer_output,
            architecture_analyzer_output=architecture_analyzer_output,
            intelligent_diagnoser_output=intelligent_diagnoser_output,
            quality_gate_output=quality_gate_output
        )

        # ç”ŸæˆæŠ¥å‘Š
        return self.generate_report(review_data=review_data, output_dir=output_dir)

    def get_available_templates(self) -> list:
        """è·å–å¯ç”¨çš„æ¨¡æ¿åˆ—è¡¨"""
        template_files = []
        if self.template_dir.exists():
            for file_path in self.template_dir.glob("*.j2"):
                template_files.append(file_path.name)
        return sorted(template_files)

    def validate_template(self, template_name: str) -> bool:
        """éªŒè¯æ¨¡æ¿æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰æ•ˆ"""
        try:
            template = self.jinja_env.get_template(template_name)
            return True
        except:
            return False