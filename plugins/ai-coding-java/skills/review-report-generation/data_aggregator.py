#!/usr/bin/env python3
"""
æ™ºèƒ½ä»£ç å®¡æŸ¥æ•°æ®èšåˆå™¨
è´Ÿè´£æ”¶é›†å’Œæ•´ç†å„ä»£ç†çš„åˆ†æç»“æœï¼Œä¸ºæŠ¥å‘Šç”Ÿæˆæä¾›ç»“æ„åŒ–æ•°æ®
"""

import json
import re
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass


@dataclass
class Issue:
    """ä»£ç é—®é¢˜æ•°æ®ç»“æ„"""
    priority: str  # "high", "medium", "low"
    category: str  # "architecture", "performance", "security", "style", etc.
    file_path: str
    line_number: Optional[int]
    description: str
    impact: str
    fix_suggestion: str
    code_example: Optional[str] = None
    estimated_time: Optional[str] = None


@dataclass
class QualityMetrics:
    """è´¨é‡æŒ‡æ ‡æ•°æ®ç»“æ„"""
    overall_score: float  # 0-100
    overall_grade: str    # A/B/C/D/F
    health_score: float   # 0-100
    architecture_score: float  # 0-100
    complexity_level: str    # "low", "medium", "high"
    performance_risk: str    # "low", "medium", "high"


class ReviewDataAggregator:
    """ä»£ç å®¡æŸ¥æ•°æ®èšåˆå™¨"""

    def __init__(self):
        self.issues: List[Issue] = []
        self.quality_metrics: Optional[QualityMetrics] = None
        self.architecture_analysis: Dict[str, Any] = {}
        self.review_summary: Dict[str, Any] = {}

    def parse_code_reviewer_output(self, output: str) -> Dict[str, Any]:
        """è§£æ code-reviewer ä»£ç†çš„è¾“å‡º"""
        data = {
            "issues": [],
            "quality_assessment": {},
            "recommendations": []
        }

        # è§£æé—®é¢˜æ¸…å•
        high_priority_issues = self._extract_issues_by_priority(output, "ğŸ”´")
        medium_priority_issues = self._extract_issues_by_priority(output, "ğŸŸ¡")
        low_priority_suggestions = self._extract_issues_by_priority(output, "ğŸŸ¢")

        data["issues"] = high_priority_issues + medium_priority_issues + low_priority_suggestions

        # è§£æè´¨é‡è¯„ä¼°
        quality_match = re.search(r'æ€»ä½“è¯„åˆ†[ï¼š:]\s*([A-F])', output)
        if quality_match:
            data["quality_assessment"]["overall_grade"] = quality_match.group(1)

        # è§£æå¥åº·åº¦è¯„åˆ†
        health_match = re.search(r'ä»£ç å¥åº·åº¦[ï¼š:]\s*(\d+)%', output)
        if health_match:
            data["quality_assessment"]["health_score"] = int(health_match.group(1))

        # è§£æå»ºè®®
        recommendations = self._extract_recommendations(output)
        data["recommendations"] = recommendations

        return data

    def parse_architecture_analyzer_output(self, output: str) -> Dict[str, Any]:
        """è§£æ architecture-analyzer ä»£ç†çš„è¾“å‡º"""
        data = {
            "service_boundaries": {},
            "architecture_patterns": [],
            "dependency_analysis": {},
            "optimization_suggestions": []
        }

        # è§£ææœåŠ¡è¾¹ç•Œè¯„ä¼°
        service_boundary_match = re.search(r'æœåŠ¡è¾¹ç•Œè¯„ä¼°[ï¼š:]\s*([^\\n]+)', output)
        if service_boundary_match:
            data["service_boundaries"]["assessment"] = service_boundary_match.group(1).strip()

        # è§£ææ¶æ„æ¨¡å¼
        patterns = re.findall(r'([A-Z][a-zA-Z]+æ¨¡å¼|[a-zA-Z]+æ¶æ„)', output)
        data["architecture_patterns"] = list(set(patterns))

        # è§£æä¼˜åŒ–å»ºè®®
        optimization_suggestions = self._extract_optimization_suggestions(output)
        data["optimization_suggestions"] = optimization_suggestions

        return data

    def parse_intelligent_diagnoser_output(self, output: str) -> Dict[str, Any]:
        """è§£æ intelligent-diagnoser ä»£ç†çš„è¾“å‡º"""
        data = {
            "code_smells": [],
            "performance_bottlenecks": [],
            "root_cause_analysis": {},
            "risk_assessment": {}
        }

        # è§£æä»£ç å¼‚å‘³
        code_smells = self._extract_code_smells(output)
        data["code_smells"] = code_smells

        # è§£ææ€§èƒ½ç“¶é¢ˆ
        bottlenecks = self._extract_performance_bottlenecks(output)
        data["performance_bottlenecks"] = bottlenecks

        return data

    def aggregate_review_data(self,
                            code_reviewer_output: str,
                            architecture_analyzer_output: str = "",
                            intelligent_diagnoser_output: str = "",
                            quality_gate_output: str = "",
                            git_summary: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """èšåˆæ‰€æœ‰ä»£ç†çš„å®¡æŸ¥æ•°æ®"""

        # è§£æå„ä»£ç†è¾“å‡º
        code_review_data = self.parse_code_reviewer_output(code_reviewer_output)
        architecture_data = self.parse_architecture_analyzer_output(architecture_analyzer_output)
        diagnoser_data = self.parse_intelligent_diagnoser_output(intelligent_diagnoser_output)

        # èšåˆé—®é¢˜æ•°æ®
        all_issues = self._aggregate_issues(code_review_data, architecture_data, diagnoser_data)

        # è®¡ç®—è´¨é‡æŒ‡æ ‡
        quality_metrics = self._calculate_quality_metrics(all_issues, code_review_data, architecture_data)

        # æ„å»ºç»¼åˆæ•°æ®
        aggregated_data = {
            "timestamp": datetime.now().isoformat(),
            "review_summary": {
                "total_issues": len(all_issues),
                "high_priority_count": len([i for i in all_issues if i.priority == "high"]),
                "medium_priority_count": len([i for i in all_issues if i.priority == "medium"]),
                "low_priority_count": len([i for i in all_issues if i.priority == "low"]),
                "files_analyzed": self._count_analyzed_files(code_reviewer_output),
                "duration": self._extract_duration(code_reviewer_output)
            },
            "quality_metrics": quality_metrics,
            "issues": all_issues,
            "architecture_analysis": {
                "service_boundaries": architecture_data.get("service_boundaries", {}),
                "architecture_patterns": architecture_data.get("architecture_patterns", []),
                "optimization_suggestions": architecture_data.get("optimization_suggestions", [])
            },
            "intelligent_insights": {
                "code_smells": diagnoser_data.get("code_smells", []),
                "performance_bottlenecks": diagnoser_data.get("performance_bottlenecks", []),
                "risk_assessment": self._assess_risks(all_issues, quality_metrics)
            },
            "recommendations": code_review_data.get("recommendations", []),
            "git_summary": git_summary or {},  # æ·»åŠ Gitæ‘˜è¦æ•°æ®
            "agent_outputs": {
                "code_reviewer": code_reviewer_output,
                "architecture_analyzer": architecture_analyzer_output,
                "intelligent_diagnoser": intelligent_diagnoser_output
            }
        }

        return aggregated_data

    def _extract_issues_by_priority(self, output: str, priority_emoji: str) -> List[Dict[str, Any]]:
        """æ ¹æ®ä¼˜å…ˆçº§è¡¨æƒ…ç¬¦å·æå–é—®é¢˜"""
        issues = []
        pattern = (f'{priority_emoji}\\s*([^\\n]+)\\n(?:.*?ä½ç½®[ï¼š:]*\\s*([^\\n]+)\\n)?'
                 f'(?:.*?å½±å“[ï¼š:]*\\s*([^\\n]+)\\n)?(?:.*?å»ºè®®[ï¼š:]*\\s*([^\\n]+)\\n)?')

        matches = re.findall(pattern, output, re.MULTILINE | re.DOTALL)

        for match in matches:
            description = match[0].strip()
            location = match[1].strip() if match[1] else "æœªæŒ‡å®š"
            impact = match[2].strip() if match[2] else "å¾…è¯„ä¼°"
            suggestion = match[3].strip() if match[3] else "éœ€è¦è¿›ä¸€æ­¥åˆ†æ"

            issues.append({
                "description": description,
                "location": location,
                "impact": impact,
                "fix_suggestion": suggestion,
                "priority": self._emoji_to_priority(priority_emoji)
            })

        return issues

    def _extract_recommendations(self, output: str) -> List[str]:
        """æå–å»ºè®®åˆ—è¡¨"""
        recommendations = []

        # æŸ¥æ‰¾å»ºè®®éƒ¨åˆ†
        rec_section_match = re.search(r'(?:å»ºè®®|æ¨è)[ï¼š:]*\\n((?:[â€¢\\-]\\s*.*\\n?)*)', output)
        if rec_section_match:
            rec_text = rec_section_match.group(1)
            recommendations = re.findall(r'[â€¢\\-]\\s*(.+)', rec_text)

        return [r.strip() for r in recommendations if r.strip()]

    def _extract_optimization_suggestions(self, output: str) -> List[Dict[str, str]]:
        """æå–æ¶æ„ä¼˜åŒ–å»ºè®®"""
        suggestions = []

        # è§£æä¼˜åŒ–å»ºè®®æ¨¡å¼
        pattern = r'(\\w+(?:ä¼˜åŒ–|æ”¹è¿›|å»ºè®®))[ï¼š:]*\\s*([^\\n]+)'
        matches = re.findall(pattern, output)

        for category, suggestion in matches:
            suggestions.append({
                "category": category,
                "suggestion": suggestion.strip()
            })

        return suggestions

    def _extract_code_smells(self, output: str) -> List[str]:
        """æå–ä»£ç å¼‚å‘³"""
        code_smells = []

        # æŸ¥æ‰¾ä»£ç å¼‚å‘³ç›¸å…³å†…å®¹
        smell_patterns = [
            r'ä»£ç å¼‚å‘³[ï¼š:]*\\s*([^\\n]+)',
            r'åå‘³é“[ï¼š:]*\\s*([^\\n]+)',
            r'å¯ç–‘ä»£ç [ï¼š:]*\\s*([^\\n]+)'
        ]

        for pattern in smell_patterns:
            matches = re.findall(pattern, output)
            code_smells.extend(matches)

        return list(set(code_smells))

    def _extract_performance_bottlenecks(self, output: str) -> List[str]:
        """æå–æ€§èƒ½ç“¶é¢ˆ"""
        bottlenecks = []

        # æŸ¥æ‰¾æ€§èƒ½ç“¶é¢ˆç›¸å…³å†…å®¹
        bottleneck_patterns = [
            r'æ€§èƒ½ç“¶é¢ˆ[ï¼š:]*\\s*([^\\n]+)',
            r'æ€§èƒ½é—®é¢˜[ï¼š:]*\\s*([^\\n]+)',
            r'æ€§èƒ½é£é™©[ï¼š:]*\\s*([^\\n]+)'
        ]

        for pattern in bottleneck_patterns:
            matches = re.findall(pattern, output)
            bottlenecks.extend(matches)

        return list(set(bottlenecks))

    def _aggregate_issues(self, code_review_data: Dict, architecture_data: Dict, diagnoser_data: Dict) -> List[Dict[str, Any]]:
        """èšåˆæ‰€æœ‰é—®é¢˜æ•°æ®"""
        all_issues = []

        # ä» code-reviewer æ•°æ®æ·»åŠ é—®é¢˜
        for issue in code_review_data.get("issues", []):
            all_issues.append({
                **issue,
                "category": "general",
                "source": "code-reviewer"
            })

        # ä» architecture-analyzer æ•°æ®æ·»åŠ é—®é¢˜
        for suggestion in architecture_data.get("optimization_suggestions", []):
            all_issues.append({
                "description": f"æ¶æ„ä¼˜åŒ–: {suggestion['suggestion']}",
                "location": "æ¶æ„å±‚é¢",
                "impact": "å½±å“ç³»ç»Ÿå¯ç»´æŠ¤æ€§å’Œæ‰©å±•æ€§",
                "fix_suggestion": suggestion['suggestion'],
                "priority": "medium",
                "category": "architecture",
                "source": "architecture-analyzer"
            })

        # ä» intelligent-diagnoser æ•°æ®æ·»åŠ é—®é¢˜
        for smell in diagnoser_data.get("code_smells", []):
            all_issues.append({
                "description": f"ä»£ç å¼‚å‘³: {smell}",
                "location": "ä»£ç å±‚é¢",
                "impact": "å½±å“ä»£ç è´¨é‡å’Œå¯è¯»æ€§",
                "fix_suggestion": "é‡æ„ç›¸å…³ä»£ç ï¼Œåº”ç”¨æœ€ä½³å®è·µ",
                "priority": "medium",
                "category": "code-quality",
                "source": "intelligent-diagnoser"
            })

        return all_issues

    def _calculate_quality_metrics(self, issues: List[Dict], code_review_data: Dict, architecture_data: Dict) -> Dict[str, Any]:
        """è®¡ç®—è´¨é‡æŒ‡æ ‡"""

        # ç»Ÿè®¡é—®é¢˜æ•°é‡
        high_count = len([i for i in issues if i.get("priority") == "high"])
        medium_count = len([i for i in issues if i.get("priority") == "medium"])
        low_count = len([i for i in issues if i.get("priority") == "low"])
        total_count = len(issues)

        # åŸºç¡€è¯„åˆ†ï¼ˆä» code-reviewer æ•°æ®è·å–ï¼‰
        health_score = code_review_data.get("quality_assessment", {}).get("health_score", 70)
        overall_grade = code_review_data.get("quality_assessment", {}).get("overall_grade", "C")

        # æ ¹æ®é—®é¢˜æ•°é‡è°ƒæ•´è¯„åˆ†
        penalty = high_count * 10 + medium_count * 5 + low_count * 2
        adjusted_score = max(0, health_score - penalty)

        # è®¡ç®—ç»¼åˆè¯„åˆ†
        architecture_score = 80 if architecture_data.get("architecture_patterns") else 60
        complexity_level = "medium"  # å¯ä»¥æ ¹æ®å®é™…ä»£ç å¤æ‚åº¦è®¡ç®—

        # ç»¼åˆè¯„åˆ†ç®—æ³•
        weights = {"architecture": 0.3, "quality": 0.25, "complexity": 0.25, "performance": 0.2}
        complexity_score = 70 if complexity_level == "low" else (50 if complexity_level == "medium" else 30)
        performance_score = max(0, 100 - high_count * 15 - medium_count * 8)

        overall_score = (
            architecture_score * weights["architecture"] +
            adjusted_score * weights["quality"] +
            complexity_score * weights["complexity"] +
            performance_score * weights["performance"]
        )

        # ç¡®å®šç­‰çº§
        if overall_score >= 90:
            grade = "A"
        elif overall_score >= 80:
            grade = "B"
        elif overall_score >= 70:
            grade = "C"
        elif overall_score >= 60:
            grade = "D"
        else:
            grade = "F"

        return {
            "overall_score": round(overall_score, 1),
            "overall_grade": grade,
            "health_score": round(adjusted_score, 1),
            "architecture_score": architecture_score,
            "complexity_level": complexity_level,
            "performance_risk": "high" if high_count > 3 else ("medium" if high_count > 0 else "low")
        }

    def _assess_risks(self, issues: List[Dict], quality_metrics: Dict) -> Dict[str, Any]:
        """è¯„ä¼°é£é™©"""
        high_count = len([i for i in issues if i["priority"] == "high"])
        overall_score = quality_metrics.get("overall_score", 70)

        if high_count > 5 or overall_score < 50:
            risk_level = "high"
            risk_description = "å‘ç°å¤šä¸ªä¸¥é‡é—®é¢˜ï¼Œå»ºè®®ç«‹å³å¤„ç†"
        elif high_count > 2 or overall_score < 70:
            risk_level = "medium"
            risk_description = "å­˜åœ¨ä¸€äº›éœ€è¦å…³æ³¨çš„é—®é¢˜"
        else:
            risk_level = "low"
            risk_description = "æ•´ä½“è´¨é‡è‰¯å¥½ï¼Œé£é™©è¾ƒä½"

        return {
            "risk_level": risk_level,
            "risk_description": risk_description,
            "technical_debt": self._assess_technical_debt(issues, quality_metrics)
        }

    def _assess_technical_debt(self, issues: List[Dict], quality_metrics: Dict) -> Dict[str, Any]:
        """è¯„ä¼°æŠ€æœ¯å€ºåŠ¡"""
        # ç®€åŒ–çš„æŠ€æœ¯å€ºåŠ¡è¯„ä¼°
        high_count = len([i for i in issues if i.get("priority") == "high"])
        medium_count = len([i for i in issues if i.get("priority") == "medium"])

        estimated_days = high_count * 3 + medium_count * 1.5  # ç²—ç•¥ä¼°ç®—

        if estimated_days > 20:
            debt_level = "high"
        elif estimated_days > 10:
            debt_level = "medium"
        else:
            debt_level = "low"

        return {
            "debt_level": debt_level,
            "estimated_fix_days": round(estimated_days, 1),
            "most_critical_categories": self._get_top_issue_categories(issues)
        }

    def _get_top_issue_categories(self, issues: List[Dict]) -> List[str]:
        """è·å–æœ€ä¸»è¦çš„é—®é¢˜ç±»åˆ«"""
        category_count = {}
        for issue in issues:
            category = issue.get("category", "general")
            category_count[category] = category_count.get(category, 0) + 1

        return sorted(category_count.keys(), key=lambda x: category_count[x], reverse=True)[:3]

    def _emoji_to_priority(self, emoji: str) -> str:
        """å°†è¡¨æƒ…ç¬¦å·è½¬æ¢ä¸ºä¼˜å…ˆçº§"""
        emoji_to_priority_map = {
            "ğŸ”´": "high",
            "ğŸŸ¡": "medium",
            "ğŸŸ¢": "low"
        }
        return emoji_to_priority_map.get(emoji, "medium")

    def _count_analyzed_files(self, output: str) -> int:
        """ç»Ÿè®¡åˆ†æçš„æ–‡ä»¶æ•°é‡"""
        # å°è¯•ä»è¾“å‡ºä¸­æå–æ–‡ä»¶æ•°é‡
        file_count_match = re.search(r'(\\d+)\\s*ä¸ªæ–‡ä»¶', output)
        if file_count_match:
            return int(file_count_match.group(1))
        return 0

    def _extract_duration(self, output: str) -> str:
        """æå–æ‰§è¡Œæ—¶é•¿"""
        # å°è¯•ä»è¾“å‡ºä¸­æå–æ—¶é•¿ä¿¡æ¯
        duration_match = re.search(r'(\\d+(?:\\.\\d+)?)\\s*(?:ç§’|åˆ†é’Ÿ|å°æ—¶)', output)
        if duration_match:
            return duration_match.group(0)
        return "æœªè®°å½•"